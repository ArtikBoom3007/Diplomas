{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "script_path = os.path.join(os.getcwd(), \"../../Scripts/\")\n",
    "sys.path.append(script_path)\n",
    "import data_generator as dgen\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import yaml\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score\n",
    "\n",
    "import mlflow\n",
    "from clearml import Task, Logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создаем таску в clearML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=87c801bd78e7465bbfb26f11bbd82285\n",
      "2024-12-04 17:34:26,987 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "ClearML results page: https://app.clear.ml/projects/7a5fbd80bb434e7793ee7a6217ce42c7/experiments/87c801bd78e7465bbfb26f11bbd82285/output/log\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "run_name = f\"Run-{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "task = Task.init(\n",
    "    project_name=\"Diploma Conv Net\",\n",
    "    task_name=run_name,\n",
    "    task_type=Task.TaskTypes.training,\n",
    ")\n",
    "\n",
    "task.set_system_tags([\"gpu_monitoring\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190, 8, 5000)\n",
      "(2, 190)\n"
     ]
    }
   ],
   "source": [
    "# Примерная функция для нормализации\n",
    "def normalize(signal):\n",
    "    return signal - np.mean(signal)\n",
    "\n",
    "\n",
    "# Класс для подготовки датасета\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.fixed_length = 5000  # Пример длины для padding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Берем данные пациента\n",
    "        ecg_signal = self.data[idx]\n",
    "\n",
    "        # Применяем нормализацию к каждому каналу\n",
    "        ecg_signal = np.array([normalize(ch) for ch in ecg_signal])\n",
    "\n",
    "        # Padding/Truncation до фиксированной длины\n",
    "        ecg_signal = self._fix_length(ecg_signal)\n",
    "\n",
    "        # Преобразование в torch.tensor\n",
    "        ecg_signal = torch.tensor(ecg_signal, dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return ecg_signal, label\n",
    "\n",
    "    def _fix_length(self, ecg_signal):\n",
    "        # Применяем padding или обрезание\n",
    "        if ecg_signal.shape[1] < self.fixed_length:\n",
    "            pad_size = self.fixed_length - ecg_signal.shape[1]\n",
    "            ecg_signal = np.pad(ecg_signal, ((0, 0), (0, pad_size)), \"constant\")\n",
    "        else:\n",
    "            ecg_signal = ecg_signal[:, : self.fixed_length]\n",
    "        return ecg_signal\n",
    "\n",
    "\n",
    "def create_weighted_sampler(labels):\n",
    "    class_counts = torch.bincount(labels)\n",
    "    class_weights = 1.0 / class_counts.float()\n",
    "    sample_weights = class_weights[labels]\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=sample_weights, num_samples=len(labels), replacement=True\n",
    "    )\n",
    "    return sampler\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"../../Data/dumped/X_train.pkl\", \"rb\") as f:\n",
    "    f.seek(0)\n",
    "    X_train = pickle.load(f)\n",
    "with open(\"../../Data/dumped/y_train.pkl\", \"rb\") as f:\n",
    "    f.seek(0)\n",
    "    y_train = pickle.load(f)\n",
    "with open(\"../../Data/dumped/X_test.pkl\", \"rb\") as f:\n",
    "    f.seek(0)\n",
    "    X_test = pickle.load(f)\n",
    "with open(\"../../Data/dumped/y_test.pkl\", \"rb\") as f:\n",
    "    f.seek(0)\n",
    "    y_test = pickle.load(f)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "y_train = np.concatenate([y_train, y_train], axis=1)\n",
    "Y_train = y_train[0].astype(\"int8\")\n",
    "Y_test = y_test[0].astype(\"int8\")\n",
    "# Y_train = F.one_hot(torch.LongTensor(y_train[0]), num_classes=2).double()\n",
    "# Y_train.double()\n",
    "# Y_test = F.one_hot(torch.LongTensor(y_test[0]), num_classes=2).double()\n",
    "# Y_test.double()\n",
    "# Y_train = y_train[0]\n",
    "# Y_test = y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерируем yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "unique_train, counts_train = np.unique(Y_train, return_counts=True)\n",
    "unique_test, counts_test = np.unique(Y_test, return_counts=True)\n",
    "train_dict = dict(zip(unique_train, counts_train))\n",
    "test_dict = dict(zip(unique_test, counts_test))\n",
    "\n",
    "# Определяем конфигурацию\n",
    "config = {\n",
    "    \"model\": {\n",
    "        \"architecture\": \"GroupedInceptionNet\",\n",
    "        \"num_channels\": 8,\n",
    "        \"num_classes\": 2,\n",
    "        \"num_groups\": 2,\n",
    "        \"parameters\": {\"learning_rate\": 0.001, \"dropout_rate\": 0.1},\n",
    "    },\n",
    "    \"optimizer\": {\"type\": \"Adam\", \"parameters\": {\"lr\": 0.001, \"weight_decay\": 1e-5}},\n",
    "    \"loss_function\": {\n",
    "        \"type\": \"FocalLoss\",\n",
    "        \"parameters\": {\"alpha\": 2.0, \"gamma\": 3.0, \"pos_weight\": [1, 4]},\n",
    "    },\n",
    "    \"dataset\": {\n",
    "        \"train_size\": 0,\n",
    "        \"test_size\": 0,\n",
    "        \"class_distribution\": {\n",
    "            \"train\": {0: int(train_dict[0]), 1: int(train_dict[1])},\n",
    "            \"test\": {0: int(test_dict[0]), 1: int(test_dict[1])},\n",
    "        },\n",
    "    },\n",
    "    \"augmentations\": {\"noise_level\": 0.04, \"shift_range\": 0.2, \"mask_prob\": 0.3},\n",
    "}\n",
    "\n",
    "# Сохраняем в файл\n",
    "with open(\"config.yaml\", \"w\") as f:\n",
    "    yaml.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGDataAugmentation:\n",
    "    def __init__(self, noise_level=0.01, shift_range=0.1, mask_prob=0.1):\n",
    "        \"\"\"\n",
    "        Аргументы:\n",
    "        noise_level (float): Уровень шума, добавляемого к сигналу.\n",
    "        shift_range (float): Максимальный сдвиг сигнала, выраженный в доле от длины.\n",
    "        mask_prob (float): Вероятность маскирования случайных интервалов.\n",
    "        \"\"\"\n",
    "        self.noise_level = noise_level\n",
    "        self.shift_range = shift_range\n",
    "        self.mask_prob = mask_prob\n",
    "\n",
    "    def add_noise(self, signal):\n",
    "        \"\"\"Добавляем гауссовский шум к сигналу.\"\"\"\n",
    "        noise = torch.randn_like(signal) * self.noise_level\n",
    "        return signal + noise\n",
    "\n",
    "    def shift_signal(self, signal):\n",
    "        \"\"\"Сдвигаем сигнал на случайное значение в пределах shift_range.\"\"\"\n",
    "        shift_amount = int(self.shift_range * signal.size(-1))\n",
    "        shift = np.random.randint(-shift_amount, shift_amount)\n",
    "        return torch.roll(signal, shifts=shift, dims=-1)\n",
    "\n",
    "    def mask_random_intervals(self, signal):\n",
    "        \"\"\"Маскируем случайные интервалы в сигнале, заменяя их на нули.\"\"\"\n",
    "        mask = torch.rand(signal.size()) < self.mask_prob\n",
    "        signal = signal.masked_fill(mask, 0)\n",
    "        return signal\n",
    "\n",
    "    def __call__(self, signal):\n",
    "        \"\"\"Применяем все аугментации.\"\"\"\n",
    "        signal = self.add_noise(signal)\n",
    "        signal = self.shift_signal(signal)\n",
    "        signal = self.mask_random_intervals(signal)\n",
    "        return signal\n",
    "\n",
    "\n",
    "data_augmentation = ECGDataAugmentation(\n",
    "    noise_level=config[\"augmentations\"][\"noise_level\"],\n",
    "    shift_range=config[\"augmentations\"][\"shift_range\"],\n",
    "    mask_prob=config[\"augmentations\"][\"mask_prob\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(380, 8, 5000)\n",
      "(2, 380)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.concatenate(\n",
    "    [X_train, np.array([data_augmentation(torch.tensor(x)).numpy() for x in X_train])],\n",
    "    axis=0,\n",
    ")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "sampler = create_weighted_sampler(torch.LongTensor(Y_train))\n",
    "train_dataset = ECGDataset(data=X_train, labels=Y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, sampler=sampler)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "\n",
    "test_dataset = ECGDataset(data=X_test, labels=Y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "config[\"dataset\"][\"train_size\"] = len(train_dataset)\n",
    "config[\"dataset\"][\"test_size\"] = len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class GroupedConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_groups):\n",
    "        super(GroupedConvBlock, self).__init__()\n",
    "        self.group_conv = nn.Conv1d(\n",
    "            in_channels, out_channels, kernel_size=3, padding=1, groups=num_groups\n",
    "        )\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.group_conv(x)\n",
    "        x = self.bn(x)\n",
    "        return self.relu(x)\n",
    "\n",
    "\n",
    "class InceptionModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(InceptionModule, self).__init__()\n",
    "        branch_channels = out_channels // 4\n",
    "\n",
    "        # 1x1 Convolution\n",
    "        self.branch1 = nn.Conv1d(in_channels, branch_channels, kernel_size=1)\n",
    "\n",
    "        # 1x1 -> 3x3 Convolution\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, branch_channels, kernel_size=1),\n",
    "            nn.Conv1d(branch_channels, branch_channels, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "        # 1x1 -> 5x5 Convolution\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, branch_channels, kernel_size=1),\n",
    "            nn.Conv1d(branch_channels, branch_channels, kernel_size=5, padding=2),\n",
    "        )\n",
    "\n",
    "        # Pooling -> 1x1 Convolution\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv1d(in_channels, branch_channels, kernel_size=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        branch3 = self.branch3(x)\n",
    "        branch4 = self.branch4(x)\n",
    "        return torch.cat([branch1, branch2, branch3, branch4], dim=1)\n",
    "\n",
    "\n",
    "class GroupedInceptionNet(nn.Module):\n",
    "    def __init__(self, num_channels=8, num_classes=3, num_groups=4):\n",
    "        super(GroupedInceptionNet, self).__init__()\n",
    "        self.input_proj = nn.Conv1d(\n",
    "            num_channels, 64, kernel_size=1\n",
    "        )  # Входной проекционный слой\n",
    "\n",
    "        # Первый блок с grouped convolution\n",
    "        self.grouped_block = GroupedConvBlock(64, 128, num_groups=num_groups)\n",
    "\n",
    "        # Inception-модуль\n",
    "        self.inception_block = InceptionModule(128, 256)\n",
    "\n",
    "        # Attention-механизм\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=256, num_heads=4, batch_first=True\n",
    "        )\n",
    "\n",
    "        # Полносвязные слои\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Входной проектор\n",
    "        x = self.input_proj(x)  # [batch_size, 64, seq_len]\n",
    "\n",
    "        # Grouped Convolution Block\n",
    "        x = self.grouped_block(x)  # [batch_size, 128, seq_len]\n",
    "\n",
    "        # Inception Block\n",
    "        x = self.inception_block(x)  # [batch_size, 256, seq_len]\n",
    "\n",
    "        # Attention\n",
    "        x = x.permute(0, 2, 1)  # [batch_size, seq_len, 256]\n",
    "        x, _ = self.attention(x, x, x)  # [batch_size, seq_len, 256]\n",
    "\n",
    "        # Усреднение по временной оси\n",
    "        x = torch.mean(x, dim=1)  # [batch_size, 256]\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        x = F.relu(self.drop(self.fc1(x)))\n",
    "        x = self.fc2(x)  # [batch_size, num_classes]\n",
    "        return x\n",
    "\n",
    "\n",
    "# Пример использования\n",
    "model = GroupedInceptionNet(\n",
    "    num_channels=config[\"model\"][\"num_channels\"],\n",
    "    num_classes=config[\"model\"][\"num_classes\"],\n",
    "    num_groups=config[\"model\"][\"num_groups\"],\n",
    ")\n",
    "\n",
    "# test = torch.zeros((16, 8, 5000))\n",
    "# model = torch.utils.checkpoint.checkpoint_sequential(functions=model, input=test, segments=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction=\"mean\"):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "        if self.reduction == \"mean\":\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.start_run()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.1797\n",
      "Epoch 2/50, Loss: 0.1754\n",
      "Epoch 3/50, Loss: 0.2086\n",
      "Epoch 4/50, Loss: 0.1688\n",
      "Epoch 5/50, Loss: 0.1721\n",
      "Epoch 6/50, Loss: 0.1733\n",
      "Epoch 7/50, Loss: 0.1731\n",
      "Epoch 8/50, Loss: 0.1740\n",
      "Epoch 9/50, Loss: 0.1653\n",
      "Epoch 10/50, Loss: 0.1496\n",
      "Epoch 11/50, Loss: 0.1494\n",
      "Epoch 12/50, Loss: 0.2100\n",
      "Epoch 13/50, Loss: 0.1617\n",
      "Epoch 14/50, Loss: 0.1444\n",
      "Epoch 15/50, Loss: 0.2412\n",
      "Epoch 16/50, Loss: 0.1673\n",
      "Epoch 17/50, Loss: 0.1682\n",
      "Epoch 18/50, Loss: 0.1761\n",
      "Epoch 19/50, Loss: 0.1748\n",
      "Epoch 20/50, Loss: 0.1737\n",
      "Epoch 21/50, Loss: 0.1730\n",
      "Epoch 22/50, Loss: 0.1734\n",
      "Epoch 23/50, Loss: 0.1737\n",
      "Epoch 24/50, Loss: 0.1735\n",
      "Epoch 25/50, Loss: 0.1732\n",
      "Epoch 26/50, Loss: 0.1733\n",
      "Epoch 27/50, Loss: 0.1732\n",
      "Epoch 28/50, Loss: 0.1735\n",
      "Epoch 29/50, Loss: 0.1734\n",
      "Epoch 30/50, Loss: 0.1732\n",
      "Epoch 31/50, Loss: 0.1733\n",
      "Epoch 32/50, Loss: 0.1734\n",
      "Epoch 33/50, Loss: 0.1734\n",
      "Epoch 34/50, Loss: 0.1734\n",
      "Epoch 35/50, Loss: 0.1734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kravchenko.artem/Projects/Diplomas/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50, Loss: 0.1733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kravchenko.artem/Projects/Diplomas/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50, Loss: 0.1733\n",
      "Epoch 38/50, Loss: 0.1735\n",
      "Epoch 39/50, Loss: 0.1735\n",
      "Epoch 40/50, Loss: 0.1734\n",
      "Epoch 41/50, Loss: 0.1734\n",
      "Epoch 42/50, Loss: 0.1734\n",
      "Epoch 43/50, Loss: 0.1733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kravchenko.artem/Projects/Diplomas/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50, Loss: 0.1733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kravchenko.artem/Projects/Diplomas/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50, Loss: 0.1734\n",
      "Epoch 46/50, Loss: 0.1732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kravchenko.artem/Projects/Diplomas/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50, Loss: 0.1735\n",
      "Epoch 48/50, Loss: 0.1733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kravchenko.artem/Projects/Diplomas/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50, Loss: 0.1733\n",
      "Epoch 50/50, Loss: 0.1734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kravchenko.artem/Projects/Diplomas/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_type = config[\"loss_function\"][\"type\"]\n",
    "\n",
    "if loss_type == \"FocalLoss\":\n",
    "    criterion = FocalLoss(\n",
    "        alpha=config[\"loss_function\"][\"parameters\"][\"alpha\"],\n",
    "        gamma=config[\"loss_function\"][\"parameters\"][\"gamma\"],\n",
    "    )\n",
    "elif loss_type == \"BCEWithLogitsLoss\":\n",
    "    pos_weight = torch.tensor(config[\"loss_function\"][\"parameters\"][\"pos_weight\"])\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown loss function type: {loss_type}\")\n",
    "\n",
    "# criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "# criterion = FocalLoss(alpha=2, gamma=3)\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=config[\"optimizer\"][\"parameters\"][\"lr\"],\n",
    "    weight_decay=config[\"optimizer\"][\"parameters\"][\"weight_decay\"],\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "scaler = torch.amp.GradScaler(\"cuda\")\n",
    "\n",
    "\n",
    "# Обучение модели\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=10, patience=10):\n",
    "    best_valid_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        for inputs, labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                outputs = model(inputs)\n",
    "                # labels.type(torch.FloatTensor)\n",
    "\n",
    "                # labels = labels.type(torch.FloatTensor) \\\n",
    "                #   .reshape((labels.shape[0], 2))epoch_loss\n",
    "\n",
    "                labels = F.one_hot(labels, num_classes=2).float()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            all_preds.extend(torch.argmax(outputs, dim=1).cpu())\n",
    "            all_labels.extend(torch.argmax(labels, dim=1).cpu())\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        recall = recall_score(all_labels, all_preds)\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        precision = precision_score(all_labels, all_preds)\n",
    "\n",
    "        Logger.current_logger().report_scalar(\"Accuracy\", \"Train\", accuracy, epoch)\n",
    "        Logger.current_logger().report_scalar(\"Loss\", \"Train\", epoch_loss, epoch)\n",
    "        Logger.current_logger().report_scalar(\"Recall\", \"Train\", recall, epoch)\n",
    "        Logger.current_logger().report_scalar(\"Precision\", \"Train\", precision, epoch)\n",
    "\n",
    "        mlflow.log_metric(\"Train Accuracy\", accuracy, step=epoch)\n",
    "        mlflow.log_metric(\"Train Loss\", epoch_loss, step=epoch)\n",
    "        mlflow.log_metric(\"Train Recall\", recall, step=epoch)\n",
    "        mlflow.log_metric(\"Train Precision\", precision, step=epoch)\n",
    "\n",
    "        # if abs(epoch_loss - best_valid_loss) > 0.001:\n",
    "        #     best_valid_loss = epoch_loss\n",
    "        #     patience_counter = 0\n",
    "        # else:\n",
    "        #     patience_counter += 1\n",
    "        #     if patience_counter >= patience:\n",
    "        #         print(\"Early stopping triggered\")\n",
    "        #         break\n",
    "\n",
    "        # if epoch_loss < best_valid_loss:\n",
    "        #     best_valid_loss = epoch_loss\n",
    "        #     print(f\"\\nBest validation loss: {best_valid_loss}\")\n",
    "        #     print(f\"\\nSaving best model for epoch: {epoch+1}\\n\")\n",
    "        #     torch.save(model.state_dict(), \"model_weights.pth\")\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "\n",
    "criterion = criterion.to(device)\n",
    "# Запуск обучения\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-04 17:43:11,071 - clearml.frameworks - INFO - Found existing registered model id=34e14fe384f640f2b495597ab8f0b272 [/home/kravchenko.artem/Projects/Diplomas/Classifiers/Grouped Conv Net/model_weights.pth] reusing it.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сохранение модели\n",
    "torch.save(model.state_dict(), \"model_weights.pth\")\n",
    "task.upload_artifact(name=\"Model Weights\", artifact_object=\"model_weights.pth\")\n",
    "\n",
    "# Сохранение конфигурации\n",
    "task.upload_artifact(name=\"Config File\", artifact_object=\"config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation recall: 0.0000\n",
      "Validation accuracy: 0.8333\n",
      "Validation precision: 0.0000\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        40\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.83        48\n",
      "   macro avg       0.42      0.50      0.45        48\n",
      "weighted avg       0.69      0.83      0.76        48\n",
      "\n",
      "Матрица несоответствий для тестовой выборки метода ЛДА:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kravchenko.artem/Projects/Diplomas/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kravchenko.artem/Projects/Diplomas/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kravchenko.artem/Projects/Diplomas/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/kravchenko.artem/Projects/Diplomas/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def validate_model(model, dataloader):\n",
    "    model = GroupedInceptionNet(num_channels=8, num_classes=2, num_groups=config[\"model\"][\"num_groups\"])\n",
    "    model.load_state_dict(torch.load(\"model_weights.pth\", weights_only=True))\n",
    "    model.eval()  # Переводим модель в режим оценки\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():  # Отключаем градиенты для валидации\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)  # Предсказания с максимальной вероятностью\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    # Преобразуем в numpy массивы\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    # all_labels = np.argmax(all_labels, axis=1)\n",
    "\n",
    "    # Считаем accuracy\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    print(f\"Validation recall: {recall:.4f}\")\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Validation accuracy: {accuracy:.4f}\")\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    print(f\"Validation precision: {precision:.4f}\")\n",
    "\n",
    "    class_names = [\"Норм. ритм\", \"Амилоидоз\"]\n",
    "\n",
    "    print(\"\\n clasification report:\\n\", classification_report(all_labels, all_preds))\n",
    "\n",
    "    print(\"Матрица несоответствий для тестовой выборки метода ЛДА:\\n\")\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    disp = ConfusionMatrixDisplay(\n",
    "        confusion_matrix(all_labels, all_preds), display_labels=class_names\n",
    "    )\n",
    "    disp.plot(cmap=\"Blues\", ax=ax)\n",
    "\n",
    "    Logger.current_logger().report_confusion_matrix(\n",
    "        title=\"Confusion Matrix\",\n",
    "        series=\"Validation Results\",\n",
    "        matrix=confusion_matrix(all_labels, all_preds),\n",
    "        yaxis_reversed=True,\n",
    "        xaxis=\"Predicted\",\n",
    "        yaxis=\"Expected\",\n",
    "        xlabels=class_names,\n",
    "        ylabels=class_names,\n",
    "    )\n",
    "\n",
    "    return recall\n",
    "\n",
    "\n",
    "# Пример вызова валидации\n",
    "test_accuracy = validate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()\n",
    "task.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
