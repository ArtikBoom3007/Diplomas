{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['new pt', 'metrics.ipynb', 'best_model_sampler_BCE_1_6.pt', 'NeuralNetwork.ipynb', 'best_model_sampler_Focal.pt', 'NN_result.csv']\n"
     ]
    }
   ],
   "source": [
    "models = os.listdir(\"./\")\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(signal):\n",
    "    return (signal - np.mean(signal)) / np.std(signal)\n",
    "\n",
    "\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.fixed_length = 5000  # Пример длины для padding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Берем данные пациента\n",
    "        ecg_signal = self.data[idx]\n",
    "\n",
    "        # Применяем нормализацию к каждому каналу\n",
    "        ecg_signal = np.array([normalize(ch) for ch in ecg_signal])\n",
    "\n",
    "        # Padding/Truncation до фиксированной длины\n",
    "        ecg_signal = self._fix_length(ecg_signal)\n",
    "\n",
    "        # Преобразование в torch.tensor\n",
    "        ecg_signal = torch.tensor(ecg_signal, dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return ecg_signal, label\n",
    "\n",
    "    def _fix_length(self, ecg_signal):\n",
    "        # Применяем padding или обрезание\n",
    "        if ecg_signal.shape[1] < self.fixed_length:\n",
    "            pad_size = self.fixed_length - ecg_signal.shape[1]\n",
    "            ecg_signal = np.pad(ecg_signal, ((0, 0), (0, pad_size)), \"constant\")\n",
    "        else:\n",
    "            ecg_signal = ecg_signal[:, : self.fixed_length]\n",
    "        return ecg_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../Data/dumped/X_test.pkl\", \"rb\") as f:\n",
    "    f.seek(0)\n",
    "    X_test = pickle.load(f)\n",
    "with open(\"../../Data/dumped/y_test.pkl\", \"rb\") as f:\n",
    "    f.seek(0)\n",
    "    y_test = pickle.load(f)\n",
    "\n",
    "Y_test = y_test[0].astype(\"int8\")\n",
    "\n",
    "test_dataset = ECGDataset(data=X_test, labels=Y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ECGDataset(data=X_test, labels=Y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ECGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGNet, self).__init__()\n",
    "\n",
    "        # Сверточные слои\n",
    "        self.conv1 = nn.Conv1d(in_channels=8, out_channels=16, kernel_size=7, padding=3)\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=16, out_channels=32, kernel_size=5, padding=2\n",
    "        )\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        # LSTM слой для захвата временных зависимостей\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=32,\n",
    "            hidden_size=64,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "\n",
    "        # Полносвязные слои\n",
    "        self.fc1 = nn.Linear(64 * 2, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)  # Предполагается 3 класса болезней\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, 8, seq_len]\n",
    "\n",
    "        # Свертка\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        # Подготовка для LSTM\n",
    "        # Меняем размер на [batch_size, seq_len, channels] для LSTM\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # LSTM\n",
    "        x, (hn, cn) = self.lstm(x)\n",
    "\n",
    "        # Берем последнее скрытое состояние LSTM\n",
    "        x = x[:, -1, :]  # [batch_size, 64*2]\n",
    "\n",
    "        # Полносвязные слои\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # [batch_size, num_classes]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiBranchECGNet(nn.Module):\n",
    "    def __init__(self, num_channels=8, num_classes=3):\n",
    "        super(MultiBranchECGNet, self).__init__()\n",
    "\n",
    "        # Ветви для каждого канала (CNN)\n",
    "        self.branches = nn.ModuleList(\n",
    "            [self.create_branch() for _ in range(num_channels)]\n",
    "        )\n",
    "\n",
    "        # Attention слой для агрегации информации между каналами\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=128, num_heads=8, batch_first=True\n",
    "        )\n",
    "\n",
    "        # Полносвязные слои для классификации\n",
    "        self.fc1 = nn.Linear(128 * num_channels, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def create_branch(self):\n",
    "        \"\"\"Создаем сверточную ветвь для каждого канала\"\"\"\n",
    "        branch = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=7, padding=3),  # Свертка с padding\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(32, 64, kernel_size=5, padding=2),  # Вторая сверточная операция\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),  # Третья сверточная операция\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "        )\n",
    "        return branch\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, num_channels, seq_len]\n",
    "\n",
    "        # Обрабатываем каждый канал через свою ветвь (CNN для каждого канала)\n",
    "        branch_outputs = []\n",
    "        for i in range(x.size(1)):  # num_channels\n",
    "            branch_output = self.branches[i](\n",
    "                x[:, i : i + 1, :]\n",
    "            )  # Обрабатываем i-й канал, [batch_size, 1, seq_len]\n",
    "            branch_outputs.append(branch_output)\n",
    "\n",
    "        # Объединяем выходы ветвей\n",
    "        out = torch.stack(\n",
    "            branch_outputs, dim=1\n",
    "        )  # [batch_size, num_channels, 128, reduced_seq_len]\n",
    "        out = out.mean(\n",
    "            dim=-1\n",
    "        )  # Усредняем по временной оси: [batch_size, num_channels, 128]\n",
    "\n",
    "        # Применяем multi-head attention для межканальной агрегации\n",
    "        out, _ = self.attention(out, out, out)  # [batch_size, num_channels, 128]\n",
    "\n",
    "        # Flatten the output\n",
    "        out = out.view(out.size(0), -1)  # [batch_size, num_channels * 128]\n",
    "\n",
    "        # Полносвязные слои для классификации\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)  # [batch_size, num_classes]\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, accuracy_score, precision_score\n",
    "\n",
    "\n",
    "def validate_model(model_path, dataloader):\n",
    "    model = torch.load(model_path)\n",
    "    # model.eval()\n",
    "    model.eval()  # Переводим модель в режим оценки\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():  # Отключаем градиенты для валидации\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)  # Предсказания с максимальной вероятностью\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    # Преобразуем в numpy массивы\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    # all_labels = np.argmax(all_labels, axis=1)\n",
    "\n",
    "    # Считаем accuracy\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    print(f\"Validation recall: {recall:.4f}\")\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Validation accuracy: {accuracy:.4f}\")\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    print(f\"Validation precision: {precision:.4f}\")\n",
    "\n",
    "    return recall, accuracy, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model_sampler_BCE_1_6.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_920534/400989797.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation recall: 1.0000\n",
      "Validation accuracy: 0.8542\n",
      "Validation precision: 0.5333\n",
      "best_model_sampler_Focal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_920534/400989797.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation recall: 0.8750\n",
      "Validation accuracy: 0.9583\n",
      "Validation precision: 0.8750\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(columns=[\"model_name\", \"precision\", \"recall\", \"accuracy\"])\n",
    "\n",
    "for name in models:\n",
    "    if not name.endswith(\".pt\"):\n",
    "        continue\n",
    "    print(name)\n",
    "    recall, accuracy, precision = validate_model(name, test_loader)\n",
    "    results_df.loc[-1] = [name, precision, recall, accuracy]\n",
    "    results_df.index = results_df.index + 1\n",
    "\n",
    "results_df.head(5)\n",
    "results_df.sort_index()\n",
    "\n",
    "results_df.to_csv(\"NN_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiBranchECGNet(nn.Module):\n",
    "    def __init__(self, num_channels=8, num_classes=3):\n",
    "        super(MultiBranchECGNet, self).__init__()\n",
    "\n",
    "        # Ветви для каждого канала (CNN)\n",
    "        self.branches = nn.ModuleList(\n",
    "            [self.create_branch() for _ in range(num_channels)]\n",
    "        )\n",
    "\n",
    "        # Attention слой для агрегации информации между каналами\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=128, num_heads=8, batch_first=True\n",
    "        )\n",
    "\n",
    "        # Линейный слой для выравнивания размерности перед attention\n",
    "        self.linear_attn = nn.Linear(num_channels * 128, 128)\n",
    "\n",
    "        # Полносвязные слои для классификации\n",
    "        self.fc1 = nn.Linear(128, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "\n",
    "    def create_branch(self):\n",
    "        \"\"\"Создаем сверточную ветвь для каждого канала\"\"\"\n",
    "        branch = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=7, padding=3),  # Свертка с padding\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(32, 64, kernel_size=5, padding=2),  # Вторая сверточная операция\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),  # Третья сверточная операция\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "        )\n",
    "        return branch\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, num_channels, seq_len]\n",
    "\n",
    "        # Обрабатываем каждый канал через свою ветвь (CNN для каждого канала)\n",
    "        branch_outputs = []\n",
    "        for i in range(x.size(1)):  # num_channels\n",
    "            branch_output = self.branches[i](\n",
    "                x[:, i : i + 1, :]\n",
    "            )  # Обрабатываем i-й канал, [batch_size, 1, seq_len]\n",
    "            branch_outputs.append(branch_output)\n",
    "\n",
    "        # Объединяем выходы ветвей\n",
    "        out = torch.stack(\n",
    "            branch_outputs, dim=1\n",
    "        )  # [batch_size, num_channels, 128, reduced_seq_len]\n",
    "\n",
    "        # out = out.mean(dim=-1)  # Усредняем по временной оси: [batch_size, num_channels, 128]\n",
    "\n",
    "        # # Применяем multi-head attention для межканальной агрегации\n",
    "        # out, _ = self.attention(out, out, out)  # [batch_size, num_channels, 128]\n",
    "\n",
    "        # # Flatten the output\n",
    "        # out = torch.flatten(out, start_dim=1, end_dim=2)  # [batch_size, num_channels * 128]\n",
    "\n",
    "        # Меняем форму, чтобы соответствовать входу MultiheadAttention: [batch_size, reduced_seq_len, num_channels * 128]\n",
    "        batch_size, num_channels, embed_dim, seq_len = out.shape\n",
    "        out = out.permute(0, 3, 1, 2).reshape(batch_size, seq_len, -1)\n",
    "\n",
    "        out = F.relu(self.linear_attn(out))\n",
    "\n",
    "        # Применяем Multihead Attention ко всей последовательности\n",
    "        out, _ = self.attention(\n",
    "            out, out, out\n",
    "        )  # [batch_size, seq_len, num_channels * 128]\n",
    "\n",
    "        # Усредняем по временной оси\n",
    "        out = out.mean(dim=1)  # [batch_size, num_channels * 128]\n",
    "\n",
    "        # Полносвязные слои для классификации\n",
    "        out = F.relu(self.drop(self.fc1(out)))\n",
    "        out = self.fc2(out)  # [batch_size, num_classes]\n",
    "        return out\n",
    "\n",
    "\n",
    "# Пример использования\n",
    "model = MultiBranchECGNet(num_channels=8, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model_new_balanced.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_920534/400989797.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation recall: 1.0000\n",
      "Validation accuracy: 0.6875\n",
      "Validation precision: 0.3478\n",
      "best_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_920534/400989797.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation recall: 0.8750\n",
      "Validation accuracy: 0.7917\n",
      "Validation precision: 0.4375\n",
      "best_model_sampler_Focal_new_att.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_920534/400989797.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation recall: 0.8750\n",
      "Validation accuracy: 0.7917\n",
      "Validation precision: 0.4375\n",
      "best_model_balance_mode_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_920534/400989797.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation recall: 0.8750\n",
      "Validation accuracy: 0.7917\n",
      "Validation precision: 0.4375\n",
      "mode3_BCE_1_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_920534/400989797.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation recall: 0.8750\n",
      "Validation accuracy: 0.8125\n",
      "Validation precision: 0.4667\n",
      "best_model_sampler_BCE_1_6_new_att.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_920534/400989797.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation recall: 0.8750\n",
      "Validation accuracy: 0.8958\n",
      "Validation precision: 0.6364\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.read_csv(\"NN_result.csv\")\n",
    "\n",
    "models = os.listdir(\"./new pt\")\n",
    "\n",
    "for name in models:\n",
    "    if not name.endswith(\".pt\"):\n",
    "        continue\n",
    "    print(name)\n",
    "    recall, accuracy, precision = validate_model(\n",
    "        os.path.join(\"./new pt/\", name), test_loader\n",
    "    )\n",
    "    results_df.loc[-1] = [name, precision, recall, accuracy]\n",
    "    results_df.index = results_df.index + 1\n",
    "\n",
    "results_df.head(5)\n",
    "results_df.sort_index()\n",
    "\n",
    "results_df.to_csv(\"NN_result.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
