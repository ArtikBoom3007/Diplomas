{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "script_path = os.path.join(os.getcwd(), \"../../Scripts/\")\n",
    "sys.path.append(script_path)\n",
    "import data_generator as dgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Примерная функция для нормализации\n",
    "def normalize(signal):\n",
    "    return (signal - np.mean(signal)) / np.std(signal)\n",
    "\n",
    "# Класс для подготовки датасета\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.fixed_length = 5000  # Пример длины для padding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Берем данные пациента\n",
    "        ecg_signal = self.data[idx]\n",
    "        \n",
    "        # Применяем нормализацию к каждому каналу\n",
    "        ecg_signal = np.array([normalize(ch) for ch in ecg_signal])\n",
    "        \n",
    "        # Padding/Truncation до фиксированной длины\n",
    "        ecg_signal = self._fix_length(ecg_signal)\n",
    "        \n",
    "        # Преобразование в torch.tensor\n",
    "        ecg_signal = torch.tensor(ecg_signal, dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        \n",
    "        return ecg_signal, label\n",
    "    \n",
    "    def _fix_length(self, ecg_signal):\n",
    "        # Применяем padding или обрезание\n",
    "        if ecg_signal.shape[1] < self.fixed_length:\n",
    "            pad_size = self.fixed_length - ecg_signal.shape[1]\n",
    "            ecg_signal = np.pad(ecg_signal, ((0, 0), (0, pad_size)), 'constant')\n",
    "        else:\n",
    "            ecg_signal = ecg_signal[:, :self.fixed_length]\n",
    "        return ecg_signal\n",
    "\n",
    "# Пример использования\n",
    "# data = список из N записей, каждая содержит 8 каналов\n",
    "# labels = список меток заболеваний\n",
    "# dgen.init(filter=True)\n",
    "# amy, amyc, norm, amy_h, amyc_h, norm_h = dgen.read_data_with_meta()\n",
    "\n",
    "# X = norm + amyc + amy\n",
    "# y = np.concatenate([np.zeros(len(norm) + len(amyc)), np.ones(len(amy))])\n",
    "\n",
    "import pickle\n",
    "with open('../../Data/dumped/X_train.pkl', 'rb') as f:\n",
    "    f.seek(0)\n",
    "    X_train = pickle.load(f)\n",
    "with open('../../Data/dumped/y_train.pkl', 'rb') as f:\n",
    "    f.seek(0)\n",
    "    y_train = pickle.load(f)\n",
    "with open('../../Data/dumped/X_test.pkl', 'rb') as f:\n",
    "    f.seek(0)\n",
    "    X_test = pickle.load(f)\n",
    "with open('../../Data/dumped/y_test.pkl', 'rb') as f:\n",
    "    f.seek(0)\n",
    "    y_test = pickle.load(f)\n",
    "\n",
    "train_dataset = ECGDataset(data=X_train, labels=y_train[0])\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = ECGDataset(data=X_test, labels=y_test[0])\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ECGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGNet, self).__init__()\n",
    "        \n",
    "        # Сверточные слои\n",
    "        self.conv1 = nn.Conv1d(in_channels=8, out_channels=16, kernel_size=7, padding=3)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=5, padding=2)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        # LSTM слой для захвата временных зависимостей\n",
    "        self.lstm = nn.LSTM(input_size=32, hidden_size=64, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # Полносвязные слои\n",
    "        self.fc1 = nn.Linear(64*2, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)  # Предполагается 3 класса болезней\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, 8, seq_len]\n",
    "        \n",
    "        # Свертка\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # Подготовка для LSTM\n",
    "        # Меняем размер на [batch_size, seq_len, channels] для LSTM\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        # LSTM\n",
    "        x, (hn, cn) = self.lstm(x)\n",
    "        \n",
    "        # Берем последнее скрытое состояние LSTM\n",
    "        x = x[:, -1, :]  # [batch_size, 64*2]\n",
    "        \n",
    "        # Полносвязные слои\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # [batch_size, num_classes]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример обучения\n",
    "model = ECGNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=25):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in dataloader:\n",
    "            # Обнуление градиентов\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Прямой проход\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Обратный проход и оптимизация\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "# Запуск обучения\n",
    "# train_model(model, train_loader, criterion, optimizer, num_epochs=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiBranchECGNet(nn.Module):\n",
    "    def __init__(self, num_channels=8, num_classes=3):\n",
    "        super(MultiBranchECGNet, self).__init__()\n",
    "        \n",
    "        # Создаем отдельную ветвь для каждого канала\n",
    "        self.branches = nn.ModuleList([self.create_branch() for _ in range(num_channels)])\n",
    "        \n",
    "        # Полносвязные слои после объединения всех ветвей\n",
    "        self.fc1 = nn.Linear(1248, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.max_pool = nn.MaxPool2d(4)\n",
    "        self.conv_1 = nn.Conv1d(256, 64, kernel_size=5, padding=2)\n",
    "        self.conv_2 = nn.Conv1d(64, 32, kernel_size=5, padding=2)\n",
    "        self.conv_3 = nn.Conv1d(32, 16, kernel_size=5, padding=2)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    \n",
    "    def create_branch(self):\n",
    "        # Каждый канал проходит через свою сверточную ветвь\n",
    "        branch = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=7, padding=3),  # Свертка с padding\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(16, 32, kernel_size=5, padding=2),  # Вторая с вертка\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "        return branch\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, num_channels, seq_len]\n",
    "        \n",
    "        # Пропускаем каждый канал через свою ветвь\n",
    "        branch_outputs = []\n",
    "        for i in range(x.size(1)):  # num_channels\n",
    "            branch_output = self.branches[i](x[:, i:i+1, :])  # Обрабатываем i-й канал\n",
    "            branch_outputs.append(branch_output)\n",
    "        \n",
    "        # Объединяем выходы всех ветвей\n",
    "        out = torch.cat(branch_outputs, dim=1)  # Соединяем по оси каналов\n",
    "\n",
    "        out = F.relu(self.conv_1(out))\n",
    "\n",
    "        out = F.relu(self.conv_2(out))\n",
    "\n",
    "        out = F.relu(self.conv_3(out))\n",
    "\n",
    "        out = self.max_pool(out)\n",
    "        \n",
    "        # Преобразуем для подачи на полносвязные слои\n",
    "        out = out.view(out.size(0), -1)  # Flatten\n",
    "        \n",
    "        # Полносвязные слои\n",
    "        out = F.relu(self.dropout(self.fc1(out)))\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Пример использования\n",
    "model = MultiBranchECGNet(num_channels=8, num_classes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class MultiBranchECGNet(nn.Module):\n",
    "#     def __init__(self, num_channels=8, num_classes=3):\n",
    "#         super(MultiBranchECGNet, self).__init__()\n",
    "        \n",
    "#         # Ветви для каждого канала (CNN)\n",
    "#         self.branches = nn.ModuleList([self.create_branch() for _ in range(num_channels)])\n",
    "        \n",
    "#         # Attention слой для агрегации информации между каналами\n",
    "#         self.attention = nn.MultiheadAttention(embed_dim=128, num_heads=8, batch_first=True)\n",
    "        \n",
    "#         # Полносвязные слои для классификации\n",
    "#         self.fc1 = nn.Linear(128 * num_channels, 256)\n",
    "#         self.fc2 = nn.Linear(256, num_classes)\n",
    "    \n",
    "#     def create_branch(self):\n",
    "#         \"\"\"Создаем сверточную ветвь для каждого канала\"\"\"\n",
    "#         branch = nn.Sequential(\n",
    "#             nn.Conv1d(1, 32, kernel_size=7, padding=3),  # Свертка с padding\n",
    "#             nn.BatchNorm1d(32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool1d(2),\n",
    "#             nn.Conv1d(32, 64, kernel_size=5, padding=2),  # Вторая сверточная операция\n",
    "#             nn.BatchNorm1d(64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool1d(2),\n",
    "#             nn.Conv1d(64, 128, kernel_size=3, padding=1),  # Третья сверточная операция\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool1d(2)\n",
    "#         )\n",
    "#         return branch\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         # x shape: [batch_size, num_channels, seq_len]\n",
    "        \n",
    "#         # Обрабатываем каждый канал через свою ветвь (CNN для каждого канала)\n",
    "#         branch_outputs = []\n",
    "#         for i in range(x.size(1)):  # num_channels\n",
    "#             branch_output = self.branches[i](x[:, i:i+1, :])  # Обрабатываем i-й канал, [batch_size, 1, seq_len]\n",
    "#             branch_outputs.append(branch_output)\n",
    "        \n",
    "#         # Объединяем выходы ветвей\n",
    "#         out = torch.stack(branch_outputs, dim=1)  # [batch_size, num_channels, 128, reduced_seq_len]\n",
    "#         out = out.mean(dim=-1)  # Усредняем по временной оси: [batch_size, num_channels, 128]\n",
    "        \n",
    "#         # Применяем multi-head attention для межканальной агрегации\n",
    "#         out, _ = self.attention(out, out, out)  # [batch_size, num_channels, 128]\n",
    "        \n",
    "#         # Flatten the output\n",
    "#         out = out.view(out.size(0), -1)  # [batch_size, num_channels * 128]\n",
    "        \n",
    "#         # Полносвязные слои для классификации\n",
    "#         out = F.relu(self.fc1(out))\n",
    "#         out = self.fc2(out)  # [batch_size, num_classes]\n",
    "        \n",
    "#         return out\n",
    "\n",
    "# # Пример использования\n",
    "# model = MultiBranchECGNet(num_channels=8, num_classes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 0.6957\n",
      "Epoch 2/25, Loss: 0.6966\n",
      "Epoch 3/25, Loss: 0.6936\n",
      "Epoch 4/25, Loss: 0.6858\n",
      "Epoch 5/25, Loss: 0.6759\n",
      "Epoch 6/25, Loss: 0.6430\n",
      "Epoch 7/25, Loss: 0.5662\n",
      "Epoch 8/25, Loss: 0.5085\n",
      "Epoch 9/25, Loss: 0.3640\n",
      "Epoch 10/25, Loss: 0.3091\n",
      "Epoch 11/25, Loss: 0.2047\n",
      "Epoch 12/25, Loss: 0.1694\n",
      "Epoch 13/25, Loss: 0.0873\n",
      "Epoch 14/25, Loss: 0.0732\n",
      "Epoch 15/25, Loss: 0.0325\n",
      "Epoch 16/25, Loss: 0.0704\n",
      "Epoch 17/25, Loss: 0.0190\n",
      "Epoch 18/25, Loss: 0.0093\n",
      "Epoch 19/25, Loss: 0.0448\n",
      "Epoch 20/25, Loss: 0.0181\n",
      "Epoch 21/25, Loss: 0.0387\n",
      "Epoch 22/25, Loss: 0.0684\n",
      "Epoch 23/25, Loss: 0.0829\n",
      "Epoch 24/25, Loss: 0.0375\n",
      "Epoch 25/25, Loss: 0.0189\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Обучение модели\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "# Запуск обучения\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1]\n",
      "[1 0 1 0 0 1 0 1 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0 0]\n",
      "Validation recall: 0.5000\n",
      "Validation accuracy: 0.4000\n",
      "Validation precision: 0.4000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, accuracy_score, precision_score\n",
    "\n",
    "def validate_model(model, dataloader):\n",
    "    model.eval()  # Переводим модель в режим оценки\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():  # Отключаем градиенты для валидации\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)  # Предсказания с максимальной вероятностью\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    # Преобразуем в numpy массивы\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    print(all_preds)\n",
    "    print(all_labels)\n",
    "    \n",
    "    # Считаем accuracy\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    print(f'Validation recall: {recall:.4f}')\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f'Validation accuracy: {accuracy:.4f}')\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    print(f'Validation precision: {precision:.4f}')\n",
    "    \n",
    "    return recall\n",
    "\n",
    "# Пример вызова валидации\n",
    "test_accuracy = validate_model(model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
