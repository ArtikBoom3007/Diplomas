{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "script_path = os.path.join(os.getcwd(), \"../../Scripts/\")\n",
    "sys.path.append(script_path)\n",
    "import data_generator as dgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Примерная функция для нормализации\n",
    "def normalize(signal):\n",
    "    return (signal - np.mean(signal)) / np.std(signal)\n",
    "\n",
    "# Класс для подготовки датасета\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.fixed_length = 5000  # Пример длины для padding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Берем данные пациента\n",
    "        ecg_signal = self.data[idx]\n",
    "        \n",
    "        # Применяем нормализацию к каждому каналу\n",
    "        ecg_signal = np.array([normalize(ch) for ch in ecg_signal])\n",
    "        \n",
    "        # Padding/Truncation до фиксированной длины\n",
    "        ecg_signal = self._fix_length(ecg_signal)\n",
    "        \n",
    "        # Преобразование в torch.tensor\n",
    "        ecg_signal = torch.tensor(ecg_signal, dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        \n",
    "        return ecg_signal, label\n",
    "    \n",
    "    def _fix_length(self, ecg_signal):\n",
    "        # Применяем padding или обрезание\n",
    "        if ecg_signal.shape[1] < self.fixed_length:\n",
    "            pad_size = self.fixed_length - ecg_signal.shape[1]\n",
    "            ecg_signal = np.pad(ecg_signal, ((0, 0), (0, pad_size)), 'constant')\n",
    "        else:\n",
    "            ecg_signal = ecg_signal[:, :self.fixed_length]\n",
    "        return ecg_signal\n",
    "\n",
    "# Пример использования\n",
    "# data = список из N записей, каждая содержит 8 каналов\n",
    "# labels = список меток заболеваний\n",
    "dgen.init(filter=True)\n",
    "amy, amyc, norm, amy_h, amyc_h, norm_h = dgen.read_data_with_meta()\n",
    "\n",
    "X = norm + amyc + amy\n",
    "y = np.concatenate([np.zeros(len(norm) + len(amyc)), np.ones(len(amy))])\n",
    "\n",
    "import pickle\n",
    "with open('../../Data/dumped/X_train.pkl', 'rb') as f:\n",
    "    f.seek(0)\n",
    "    X_train = pickle.load(f)\n",
    "with open('../../Data/dumped/y_train.pkl', 'rb') as f:\n",
    "    f.seek(0)\n",
    "    y_train = pickle.load(f)\n",
    "with open('../../Data/dumped/X_test.pkl', 'rb') as f:\n",
    "    f.seek(0)\n",
    "    X_test = pickle.load(f)\n",
    "with open('../../Data/dumped/y_test.pkl', 'rb') as f:\n",
    "    f.seek(0)\n",
    "    y_test = pickle.load(f)\n",
    "\n",
    "train_dataset = ECGDataset(data=X_train, labels=y_train[0])\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = ECGDataset(data=X_test, labels=y_test[0])\n",
    "test_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ECGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGNet, self).__init__()\n",
    "        \n",
    "        # Сверточные слои\n",
    "        self.conv1 = nn.Conv1d(in_channels=8, out_channels=16, kernel_size=7, padding=3)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=5, padding=2)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        # LSTM слой для захвата временных зависимостей\n",
    "        self.lstm = nn.LSTM(input_size=32, hidden_size=64, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # Полносвязные слои\n",
    "        self.fc1 = nn.Linear(64*2, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)  # Предполагается 3 класса болезней\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, 8, seq_len]\n",
    "        \n",
    "        # Свертка\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # Подготовка для LSTM\n",
    "        # Меняем размер на [batch_size, seq_len, channels] для LSTM\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        # LSTM\n",
    "        x, (hn, cn) = self.lstm(x)\n",
    "        \n",
    "        # Берем последнее скрытое состояние LSTM\n",
    "        x = x[:, -1, :]  # [batch_size, 64*2]\n",
    "        \n",
    "        # Полносвязные слои\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # [batch_size, num_classes]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 1.0670\n",
      "Epoch 2/25, Loss: 0.9333\n",
      "Epoch 3/25, Loss: 0.6982\n",
      "Epoch 4/25, Loss: 0.6352\n",
      "Epoch 5/25, Loss: 0.5876\n",
      "Epoch 6/25, Loss: 0.5879\n",
      "Epoch 7/25, Loss: 0.5789\n",
      "Epoch 8/25, Loss: 0.5828\n",
      "Epoch 9/25, Loss: 0.5774\n",
      "Epoch 10/25, Loss: 0.5644\n",
      "Epoch 11/25, Loss: 0.5670\n",
      "Epoch 12/25, Loss: 0.5508\n",
      "Epoch 13/25, Loss: 0.5409\n",
      "Epoch 14/25, Loss: 0.5299\n",
      "Epoch 15/25, Loss: 0.5184\n",
      "Epoch 16/25, Loss: 0.4956\n",
      "Epoch 17/25, Loss: 0.4914\n",
      "Epoch 18/25, Loss: 0.5199\n",
      "Epoch 19/25, Loss: 0.5034\n",
      "Epoch 20/25, Loss: 0.4986\n",
      "Epoch 21/25, Loss: 0.4977\n",
      "Epoch 22/25, Loss: 0.4771\n",
      "Epoch 23/25, Loss: 0.4704\n",
      "Epoch 24/25, Loss: 0.4515\n",
      "Epoch 25/25, Loss: 0.4388\n"
     ]
    }
   ],
   "source": [
    "# Пример обучения\n",
    "model = ECGNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=25):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in dataloader:\n",
    "            # Обнуление градиентов\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Прямой проход\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Обратный проход и оптимизация\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "# Запуск обучения\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiBranchECGNet(nn.Module):\n",
    "    def __init__(self, num_channels=8, num_classes=3):\n",
    "        super(MultiBranchECGNet, self).__init__()\n",
    "        \n",
    "        # Создаем отдельную ветвь для каждого канала\n",
    "        self.branches = nn.ModuleList([self.create_branch() for _ in range(num_channels)])\n",
    "        \n",
    "        # Полносвязные слои после объединения всех ветвей\n",
    "        self.fc1 = nn.Linear(320000, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def create_branch(self):\n",
    "        # Каждый канал проходит через свою сверточную ветвь\n",
    "        branch = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=7, padding=3),  # Свертка с padding\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(16, 32, kernel_size=5, padding=2),  # Вторая с вертка\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "        return branch\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, num_channels, seq_len]\n",
    "        \n",
    "        # Пропускаем каждый канал через свою ветвь\n",
    "        branch_outputs = []\n",
    "        for i in range(x.size(1)):  # num_channels\n",
    "            branch_output = self.branches[i](x[:, i:i+1, :])  # Обрабатываем i-й канал\n",
    "            branch_outputs.append(branch_output)\n",
    "        \n",
    "        # Объединяем выходы всех ветвей\n",
    "        out = torch.cat(branch_outputs, dim=1)  # Соединяем по оси каналов\n",
    "        \n",
    "        # Преобразуем для подачи на полносвязные слои\n",
    "        out = out.view(out.size(0), -1)  # Flatten\n",
    "        \n",
    "        # Полносвязные слои\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Пример использования\n",
    "model = MultiBranchECGNet(num_channels=8, num_classes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 9.6126\n",
      "Epoch 2/25, Loss: 2.3094\n",
      "Epoch 3/25, Loss: 1.6491\n",
      "Epoch 4/25, Loss: 0.6087\n",
      "Epoch 5/25, Loss: 0.4328\n",
      "Epoch 6/25, Loss: 0.2854\n",
      "Epoch 7/25, Loss: 0.2050\n",
      "Epoch 8/25, Loss: 0.1287\n",
      "Epoch 9/25, Loss: 0.0657\n",
      "Epoch 10/25, Loss: 0.0266\n",
      "Epoch 11/25, Loss: 0.0108\n",
      "Epoch 12/25, Loss: 0.0054\n",
      "Epoch 13/25, Loss: 0.0020\n",
      "Epoch 14/25, Loss: 0.0009\n",
      "Epoch 15/25, Loss: 0.0004\n",
      "Epoch 16/25, Loss: 0.0002\n",
      "Epoch 17/25, Loss: 0.0001\n",
      "Epoch 18/25, Loss: 0.0001\n",
      "Epoch 19/25, Loss: 0.0001\n",
      "Epoch 20/25, Loss: 0.0001\n",
      "Epoch 21/25, Loss: 0.0001\n",
      "Epoch 22/25, Loss: 0.0000\n",
      "Epoch 23/25, Loss: 0.0000\n",
      "Epoch 24/25, Loss: 0.0000\n",
      "Epoch 25/25, Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Обучение модели\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "# Запуск обучения\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def validate_model(model, dataloader):\n",
    "    model.eval()  # Переводим модель в режим оценки\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():  # Отключаем градиенты для валидации\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)  # Предсказания с максимальной вероятностью\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    # Преобразуем в numpy массивы\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    \n",
    "    # Считаем accuracy\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    print(f'Validation recall: {recall:.4f}')\n",
    "    \n",
    "    return recall\n",
    "\n",
    "# Пример вызова валидации\n",
    "test_accuracy = validate_model(model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
