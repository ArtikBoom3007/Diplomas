{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "script_path = os.path.join(os.getcwd(), \"../../Scripts/\")\n",
    "sys.path.append(script_path)\n",
    "import data_generator as dgen\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import yaml\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score\n",
    "\n",
    "import mlflow\n",
    "from clearml import Task, Logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создаем таску в clearML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=09c7063d90b64876a9e51fdeb311d439\n",
      "2024-11-25 14:25:50,981 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "ClearML results page: https://app.clear.ml/projects/fb3fda3d43384b2d8e49fef268418091/experiments/09c7063d90b64876a9e51fdeb311d439/output/log\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "run_name = f\"Run-{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "task = Task.init(\n",
    "    project_name=\"Diploma Multibranch net\",\n",
    "    task_name=run_name,\n",
    "    task_type=Task.TaskTypes.training,\n",
    ")\n",
    "\n",
    "task.set_system_tags([\"gpu_monitoring\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190, 8, 5000)\n",
      "(2, 190)\n"
     ]
    }
   ],
   "source": [
    "# Примерная функция для нормализации\n",
    "def normalize(signal):\n",
    "    return (signal - np.mean(signal)) / np.std(signal)\n",
    "\n",
    "\n",
    "# Класс для подготовки датасета\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.fixed_length = 5000  # Пример длины для padding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Берем данные пациента\n",
    "        ecg_signal = self.data[idx]\n",
    "\n",
    "        # Применяем нормализацию к каждому каналу\n",
    "        ecg_signal = np.array([normalize(ch) for ch in ecg_signal])\n",
    "\n",
    "        # Padding/Truncation до фиксированной длины\n",
    "        ecg_signal = self._fix_length(ecg_signal)\n",
    "\n",
    "        # Преобразование в torch.tensor\n",
    "        ecg_signal = torch.tensor(ecg_signal, dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return ecg_signal, label\n",
    "\n",
    "    def _fix_length(self, ecg_signal):\n",
    "        # Применяем padding или обрезание\n",
    "        if ecg_signal.shape[1] < self.fixed_length:\n",
    "            pad_size = self.fixed_length - ecg_signal.shape[1]\n",
    "            ecg_signal = np.pad(ecg_signal, ((0, 0), (0, pad_size)), \"constant\")\n",
    "        else:\n",
    "            ecg_signal = ecg_signal[:, : self.fixed_length]\n",
    "        return ecg_signal\n",
    "\n",
    "\n",
    "def create_weighted_sampler(labels):\n",
    "    class_counts = torch.bincount(labels)\n",
    "    class_weights = 1.0 / class_counts.float()\n",
    "    sample_weights = class_weights[labels]\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=sample_weights, num_samples=len(labels), replacement=True\n",
    "    )\n",
    "    return sampler\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"../../Data/dumped/X_train.pkl\", \"rb\") as f:\n",
    "    f.seek(0)\n",
    "    X_train = pickle.load(f)\n",
    "with open(\"../../Data/dumped/y_train.pkl\", \"rb\") as f:\n",
    "    f.seek(0)\n",
    "    y_train = pickle.load(f)\n",
    "with open(\"../../Data/dumped/X_test.pkl\", \"rb\") as f:\n",
    "    f.seek(0)\n",
    "    X_test = pickle.load(f)\n",
    "with open(\"../../Data/dumped/y_test.pkl\", \"rb\") as f:\n",
    "    f.seek(0)\n",
    "    y_test = pickle.load(f)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "y_train = np.concatenate([y_train, y_train], axis=1)\n",
    "Y_train = y_train[0].astype(\"int8\")\n",
    "Y_test = y_test[0].astype(\"int8\")\n",
    "# Y_train = F.one_hot(torch.LongTensor(y_train[0]), num_classes=2).double()\n",
    "# Y_train.double()\n",
    "# Y_test = F.one_hot(torch.LongTensor(y_test[0]), num_classes=2).double()\n",
    "# Y_test.double()\n",
    "# Y_train = y_train[0]\n",
    "# Y_test = y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерируем yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "unique_train, counts_train = np.unique(Y_train, return_counts=True)\n",
    "unique_test, counts_test = np.unique(Y_test, return_counts=True)\n",
    "train_dict = dict(zip(unique_train, counts_train))\n",
    "test_dict = dict(zip(unique_test, counts_test))\n",
    "\n",
    "# Определяем конфигурацию\n",
    "config = {\n",
    "    \"model\": {\n",
    "        \"architecture\": \"MultiBranchECGNet\",\n",
    "        \"num_channels\": 8,\n",
    "        \"num_classes\": 2,\n",
    "        \"parameters\": {\"learning_rate\": 0.001, \"dropout_rate\": 0.1},\n",
    "    },\n",
    "    \"optimizer\": {\"type\": \"Adam\", \"parameters\": {\"lr\": 0.001, \"weight_decay\": 1e-5}},\n",
    "    \"loss_function\": {\n",
    "        \"type\": \"FocalLoss\",\n",
    "        \"parameters\": {\"alpha\": 1.0, \"gamma\": 1, \"pos_weight\": [1, 4]},\n",
    "    },\n",
    "    \"dataset\": {\n",
    "        \"train_size\": 0,\n",
    "        \"test_size\": 0,\n",
    "        \"class_distribution\": {\n",
    "            \"train\": {0: int(train_dict[0]), 1: int(train_dict[1])},\n",
    "            \"test\": {0: int(test_dict[0]), 1: int(test_dict[1])},\n",
    "        },\n",
    "    },\n",
    "    \"augmentations\": {\"noise_level\": 0.04, \"shift_range\": 0.2, \"mask_prob\": 0.3},\n",
    "}\n",
    "\n",
    "# Сохраняем в файл\n",
    "with open(\"config.yaml\", \"w\") as f:\n",
    "    yaml.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGDataAugmentation:\n",
    "    def __init__(self, noise_level=0.01, shift_range=0.1, mask_prob=0.1):\n",
    "        \"\"\"\n",
    "        Аргументы:\n",
    "        noise_level (float): Уровень шума, добавляемого к сигналу.\n",
    "        shift_range (float): Максимальный сдвиг сигнала, выраженный в доле от длины.\n",
    "        mask_prob (float): Вероятность маскирования случайных интервалов.\n",
    "        \"\"\"\n",
    "        self.noise_level = noise_level\n",
    "        self.shift_range = shift_range\n",
    "        self.mask_prob = mask_prob\n",
    "\n",
    "    def add_noise(self, signal):\n",
    "        \"\"\"Добавляем гауссовский шум к сигналу.\"\"\"\n",
    "        noise = torch.randn_like(signal) * self.noise_level\n",
    "        return signal + noise\n",
    "\n",
    "    def shift_signal(self, signal):\n",
    "        \"\"\"Сдвигаем сигнал на случайное значение в пределах shift_range.\"\"\"\n",
    "        shift_amount = int(self.shift_range * signal.size(-1))\n",
    "        shift = np.random.randint(-shift_amount, shift_amount)\n",
    "        return torch.roll(signal, shifts=shift, dims=-1)\n",
    "\n",
    "    def mask_random_intervals(self, signal):\n",
    "        \"\"\"Маскируем случайные интервалы в сигнале, заменяя их на нули.\"\"\"\n",
    "        mask = torch.rand(signal.size()) < self.mask_prob\n",
    "        signal = signal.masked_fill(mask, 0)\n",
    "        return signal\n",
    "\n",
    "    def __call__(self, signal):\n",
    "        \"\"\"Применяем все аугментации.\"\"\"\n",
    "        signal = self.add_noise(signal)\n",
    "        signal = self.shift_signal(signal)\n",
    "        signal = self.mask_random_intervals(signal)\n",
    "        return signal\n",
    "\n",
    "\n",
    "data_augmentation = ECGDataAugmentation(\n",
    "    noise_level=config[\"augmentations\"][\"noise_level\"],\n",
    "    shift_range=config[\"augmentations\"][\"shift_range\"],\n",
    "    mask_prob=config[\"augmentations\"][\"mask_prob\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(380, 8, 5000)\n",
      "(2, 380)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.concatenate(\n",
    "    [X_train, np.array([data_augmentation(torch.tensor(x)).numpy() for x in X_train])],\n",
    "    axis=0,\n",
    ")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "sampler = create_weighted_sampler(torch.LongTensor(Y_train))\n",
    "train_dataset = ECGDataset(data=X_train, labels=Y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "\n",
    "test_dataset = ECGDataset(data=X_test, labels=Y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "config[\"dataset\"][\"train_size\"] = len(train_dataset)\n",
    "config[\"dataset\"][\"test_size\"] = len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ECGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGNet, self).__init__()\n",
    "\n",
    "        # Сверточные слои\n",
    "        self.conv1 = nn.Conv1d(in_channels=8, out_channels=16, kernel_size=7, padding=3)\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=16, out_channels=32, kernel_size=5, padding=2\n",
    "        )\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        # LSTM слой для захвата временных зависимостей\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=32,\n",
    "            hidden_size=64,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "\n",
    "        # Полносвязные слои\n",
    "        self.fc1 = nn.Linear(64 * 2, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)  # Предполагается 3 класса болезней\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, 8, seq_len]\n",
    "\n",
    "        # Свертка\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        # Подготовка для LSTM\n",
    "        # Меняем размер на [batch_size, seq_len, channels] для LSTM\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # LSTM\n",
    "        x, (hn, cn) = self.lstm(x)\n",
    "\n",
    "        # Берем последнее скрытое состояние LSTM\n",
    "        x = x[:, -1, :]  # [batch_size, 64*2]\n",
    "\n",
    "        # Полносвязные слои\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # [batch_size, num_classes]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiBranchECGNet(nn.Module):\n",
    "    def __init__(self, num_channels=8, num_classes=3):\n",
    "        super(MultiBranchECGNet, self).__init__()\n",
    "\n",
    "        # Ветви для каждого канала (CNN)\n",
    "        self.branches = nn.ModuleList(\n",
    "            [self.create_branch() for _ in range(num_channels)]\n",
    "        )\n",
    "\n",
    "        # Attention слой для агрегации информации между каналами\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=128, num_heads=8, batch_first=True\n",
    "        )\n",
    "\n",
    "        # Линейный слой для выравнивания размерности перед attention\n",
    "        self.linear_attn = nn.Linear(num_channels * 128, 128)\n",
    "\n",
    "        # Полносвязные слои для классификации\n",
    "        self.fc1 = nn.Linear(128, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        self.drop = nn.Dropout(p=config[\"model\"][\"parameters\"][\"dropout_rate\"])\n",
    "\n",
    "    def create_branch(self):\n",
    "        \"\"\"Создаем сверточную ветвь для каждого канала\"\"\"\n",
    "        branch = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=7, padding=3),  # Свертка с padding\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(32, 64, kernel_size=5, padding=2),  # Вторая сверточная операция\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),  # Третья сверточная операция\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "        )\n",
    "        return branch\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, num_channels, seq_len]\n",
    "\n",
    "        # Обрабатываем каждый канал через свою ветвь (CNN для каждого канала)\n",
    "        branch_outputs = []\n",
    "        for i in range(x.size(1)):  # num_channels\n",
    "            branch_output = self.branches[i](\n",
    "                x[:, i : i + 1, :]\n",
    "            )  # Обрабатываем i-й канал, [batch_size, 1, seq_len]\n",
    "            branch_outputs.append(branch_output)\n",
    "\n",
    "        # Объединяем выходы ветвей\n",
    "        out = torch.stack(\n",
    "            branch_outputs, dim=1\n",
    "        )  # [batch_size, num_channels, 128, reduced_seq_len]\n",
    "\n",
    "        # out = out.mean(dim=-1)  # Усредняем по временной оси: [batch_size, num_channels, 128]\n",
    "\n",
    "        # # Применяем multi-head attention для межканальной агрегации\n",
    "        # out, _ = self.attention(out, out, out)  # [batch_size, num_channels, 128]\n",
    "\n",
    "        # # Flatten the output\n",
    "        # out = torch.flatten(out, start_dim=1, end_dim=2)  # [batch_size, num_channels * 128]\n",
    "\n",
    "        # Меняем форму, чтобы соответствовать входу MultiheadAttention: [batch_size, reduced_seq_len, num_channels * 128]\n",
    "        batch_size, num_channels, embed_dim, seq_len = out.shape\n",
    "        out = out.permute(0, 3, 1, 2).reshape(batch_size, seq_len, -1)\n",
    "\n",
    "        out = F.relu(self.linear_attn(out))\n",
    "\n",
    "        # Применяем Multihead Attention ко всей последовательности\n",
    "        out, _ = self.attention(\n",
    "            out, out, out\n",
    "        )  # [batch_size, seq_len, num_channels * 128]\n",
    "\n",
    "        # Усредняем по временной оси\n",
    "        out = out.mean(dim=1)  # [batch_size, num_channels * 128]\n",
    "\n",
    "        # Полносвязные слои для классификации\n",
    "        out = F.relu(self.drop(self.fc1(out)))\n",
    "        out = self.fc2(out)  # [batch_size, num_classes]\n",
    "        return out\n",
    "\n",
    "\n",
    "# Пример использования\n",
    "model = MultiBranchECGNet(num_channels=8, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction=\"mean\"):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "        if self.reduction == \"mean\":\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.3445\n",
      "Epoch 2/50, Loss: 0.3081\n",
      "Epoch 3/50, Loss: 0.2930\n",
      "Epoch 4/50, Loss: 0.2811\n",
      "Epoch 5/50, Loss: 0.2379\n",
      "Epoch 6/50, Loss: 0.2332\n",
      "Epoch 7/50, Loss: 0.1838\n",
      "Epoch 8/50, Loss: 0.1988\n",
      "Epoch 9/50, Loss: 0.1887\n",
      "Epoch 10/50, Loss: 0.2060\n",
      "Epoch 11/50, Loss: 0.2134\n",
      "Epoch 12/50, Loss: 0.1313\n",
      "Epoch 13/50, Loss: 0.1703\n",
      "Epoch 14/50, Loss: 0.1172\n",
      "Epoch 15/50, Loss: 0.1524\n",
      "Epoch 16/50, Loss: 0.0846\n",
      "Epoch 17/50, Loss: 0.1084\n",
      "Epoch 18/50, Loss: 0.0909\n",
      "Epoch 19/50, Loss: 0.0825\n",
      "Epoch 20/50, Loss: 0.1170\n",
      "Epoch 21/50, Loss: 0.0977\n",
      "Epoch 22/50, Loss: 0.0756\n",
      "Epoch 23/50, Loss: 0.0772\n",
      "Epoch 24/50, Loss: 0.0474\n",
      "Epoch 25/50, Loss: 0.0355\n",
      "Epoch 26/50, Loss: 0.0407\n",
      "Epoch 27/50, Loss: 0.0496\n",
      "Epoch 28/50, Loss: 0.0357\n",
      "Epoch 29/50, Loss: 0.0654\n",
      "Epoch 30/50, Loss: 0.0592\n",
      "Epoch 31/50, Loss: 0.0592\n",
      "Epoch 32/50, Loss: 0.0467\n",
      "Epoch 33/50, Loss: 0.0225\n",
      "Epoch 34/50, Loss: 0.0152\n",
      "Epoch 35/50, Loss: 0.0053\n",
      "Epoch 36/50, Loss: 0.0016\n",
      "Epoch 37/50, Loss: 0.0005\n",
      "Epoch 38/50, Loss: 0.0432\n",
      "Epoch 39/50, Loss: 0.1122\n",
      "Epoch 40/50, Loss: 0.0634\n",
      "Epoch 41/50, Loss: 0.0298\n",
      "Epoch 42/50, Loss: 0.0220\n",
      "Epoch 43/50, Loss: 0.0215\n",
      "Epoch 44/50, Loss: 0.0250\n",
      "Epoch 45/50, Loss: 0.0191\n",
      "Epoch 46/50, Loss: 0.0179\n",
      "Epoch 47/50, Loss: 0.0437\n",
      "Epoch 48/50, Loss: 0.0851\n",
      "Epoch 49/50, Loss: 0.0509\n",
      "Epoch 50/50, Loss: 0.0197\n"
     ]
    }
   ],
   "source": [
    "loss_type = config[\"loss_function\"][\"type\"]\n",
    "\n",
    "if loss_type == \"FocalLoss\":\n",
    "    criterion = FocalLoss(\n",
    "        alpha=config[\"loss_function\"][\"parameters\"][\"alpha\"],\n",
    "        gamma=config[\"loss_function\"][\"parameters\"][\"gamma\"],\n",
    "    )\n",
    "elif loss_type == \"BCEWithLogitsLoss\":\n",
    "    pos_weight = torch.tensor(config[\"loss_function\"][\"parameters\"][\"pos_weight\"])\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown loss function type: {loss_type}\")\n",
    "\n",
    "# criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "# criterion = FocalLoss(alpha=2, gamma=3)\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=config[\"optimizer\"][\"parameters\"][\"lr\"],\n",
    "    weight_decay=config[\"optimizer\"][\"parameters\"][\"weight_decay\"],\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Обучение модели\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=10, patience=10):\n",
    "    best_valid_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        for inputs, labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            # labels.type(torch.FloatTensor)\n",
    "\n",
    "            # labels = labels.type(torch.FloatTensor) \\\n",
    "            #   .reshape((labels.shape[0], 2))epoch_loss\n",
    "\n",
    "            labels = F.one_hot(labels, num_classes=2).float()\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            all_preds.extend(torch.argmax(outputs, dim=1).cpu())\n",
    "            all_labels.extend(torch.argmax(labels, dim=1).cpu())\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        recall = recall_score(all_labels, all_preds)\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        precision = precision_score(all_labels, all_preds)\n",
    "\n",
    "        Logger.current_logger().report_scalar(\"Accuracy\", \"Train\", accuracy, epoch)\n",
    "        Logger.current_logger().report_scalar(\"Loss\", \"Train\", epoch_loss, epoch)\n",
    "        Logger.current_logger().report_scalar(\"Recall\", \"Train\", recall, epoch)\n",
    "        Logger.current_logger().report_scalar(\"Precision\", \"Train\", precision, epoch)\n",
    "\n",
    "        mlflow.log_metric(\"Train Accuracy\", accuracy, step=epoch)\n",
    "        mlflow.log_metric(\"Train Loss\", epoch_loss, step=epoch)\n",
    "        mlflow.log_metric(\"Train Recall\", recall, step=epoch)\n",
    "        mlflow.log_metric(\"Train Precision\", precision, step=epoch)\n",
    "\n",
    "        if abs(epoch_loss - best_valid_loss) > 0.001:\n",
    "            best_valid_loss = epoch_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "        # if epoch_loss < best_valid_loss:\n",
    "        #     best_valid_loss = epoch_loss\n",
    "        #     print(f\"\\nBest validation loss: {best_valid_loss}\")\n",
    "        #     print(f\"\\nSaving best model for epoch: {epoch+1}\\n\")\n",
    "        #     torch.save(model.state_dict(), \"model_weights.pth\")\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "\n",
    "# Запуск обучения\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-25 14:27:06,081 - clearml.frameworks - INFO - Found existing registered model id=078a530219b44bd5b8f841b1a246c02b [/home/kravchenko.artem/Projects/Diplomas/Classifiers/NN/model_weights.pth] reusing it.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сохранение модели\n",
    "torch.save(model.state_dict(), \"model_weights.pth\")\n",
    "task.upload_artifact(name=\"Model Weights\", artifact_object=\"model_weights.pth\")\n",
    "\n",
    "# Сохранение конфигурации\n",
    "task.upload_artifact(name=\"Config File\", artifact_object=\"config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation recall: 0.7500\n",
      "Validation accuracy: 0.7708\n",
      "Validation precision: 0.4000\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.78      0.85        40\n",
      "           1       0.40      0.75      0.52         8\n",
      "\n",
      "    accuracy                           0.77        48\n",
      "   macro avg       0.67      0.76      0.69        48\n",
      "weighted avg       0.85      0.77      0.79        48\n",
      "\n",
      "Матрица несоответствий для тестовой выборки метода ЛДА:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfwAAAGaCAYAAADq//FUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9KklEQVR4nO3deVxUdfv/8fcAMqAspqYI4oqg5O6dxVfLJXPpvlNv9eeSJqTpbbeaC2q2oKh1e+duZVaCmn2zslwq275mqWmaSdly34ZppphopQmKiQrn94czkyNgjDM4w8zr6eM8as458znXkHHNdZ3POcdkGIYhAADg1fzcHQAAACh7JHwAAHwACR8AAB9AwgcAwAeQ8AEA8AEkfAAAfAAJHwAAHxDg7gAAAPAE586d0/nz510yVmBgoIKCglwylquQ8AEAPu/cuXMKDq0qXTzrkvEiIiJ08OBBj0r6JHwAgM87f/68dPGszPGJkn+gc4MVnNex/76o8+fPk/ABAPBIAUEyOZnwDZNnTo8j4QMAYGWSZDI5P4YH8syvIQAAwKWo8AEAsDL5XVqcHcMDkfABALAymVzQ0vfMnr5nfg0BAAAuRYUPAIAVLX0AAHwALX0AAFAWlixZombNmiksLExhYWFKSEjQe++9Z9t+7tw5jRo1SlWrVlVISIj69Omj48ePO3wcEj4AADZ+f7T1r3VxMLXWqlVL//73v5WRkaHdu3erU6dO6tmzp/7zn/9IksaPH6+3335br7/+urZs2aKjR4+qd+/eDn8yk2EYhsPvAgDAi+Tm5io8PFzmv4yTKcDs1FjGxXzl716orKwshYWF2dabzWaZzaUbu0qVKpozZ4769u2rG2+8UatWrVLfvn0lSd99950aN26sHTt26NZbby11XFT4AACUgejoaIWHh9uWWbNm/el7CgoK9OqrryovL08JCQnKyMjQhQsX1LlzZ9s+jRo1Uu3atbVjxw6H4mHSHgAAVi6cpV9chV+Sb775RgkJCTp37pxCQkK0bt06xcfHa8+ePQoMDFTlypXt9q9Ro4aOHTvmUFgkfAAArFw4S986Ca804uLitGfPHuXk5OiNN95QYmKitmzZ4lwcVyDhAwDgZoGBgYqJiZEktW7dWp9//rkWLVqk/v376/z58zp16pRdlX/8+HFFREQ4dAzO4QMAYOXsDH1XnBKQVFhYqPz8fLVu3VoVKlTQpk2bbNsyMzN1+PBhJSQkODQmFT4AAFZuuPHOww8/rO7du6t27do6ffq0Vq1apc2bN+uDDz5QeHi4hg0bpgkTJqhKlSoKCwvTmDFjlJCQ4NAMfYmEDwCAW/38888aMmSIsrOzFR4ermbNmumDDz7QnXfeKUlasGCB/Pz81KdPH+Xn56tr16569tlnHT4O1+EDAHye7Tr8hCmuuQ5/x7+Vk5NT6kl71wMVPgAAViaTCy7L4176AADATajwAQCw8jNdWpwdwwOR8AEAsHLhnfY8jWdGBQAAXIoKHwAAKzdch3+9kPABALCipQ8AAMozKnwAAKxo6QMA4ANo6QMAgPKMCh8AACta+gAA+ABa+gAAoDyjwgcAwIqWPgAAvsAFLX0PbZ6T8H1EYWGhjh49qtDQUJk89NsnADjCMAydPn1akZGR8vPzzCTrSUj4PuLo0aOKjo52dxgA4HJZWVmqVauWawajpY/yLjQ0VJIUGJ8ok3+gm6OBt3t35WPuDgE+IO/MafW4rYnt95tLmEwumKVPwocbWdv4Jv9AEj7KXKXQMHeHAB/CacrSIeEDAGDlxdfhk/ABALDy4nP4nvk1BAAAuBQVPgAAVrT0AQDwAbT0AQBAeUaFDwCAFS19AAB8AC19AABQnlHhAwBgYTKZnL9zn4dW+CR8AAAsvDnh09IHAMAHUOEDAGBlsizOjuGBSPgAAFjQ0gcAAOUaFT4AABbeXOGT8AEAsPDmhE9LHwAAH0CFDwCAhTdX+CR8AACsvPiyPFr6AAD4ACp8AAAsaOkDAOADLj0d19mE75pYXI2WPgAAPoAKHwAAC5Nc0NL30BKfhA8AgIU3n8OnpQ8AgA+gwgcAwMqLr8Mn4QMAYOWClr5BSx8AALgLFT4AABaumLTn/Cz/skHCBwDAwpsTPi19AAB8ABU+AABWzNIHAMD70dIHAABlYtasWbr55psVGhqq6tWrq1evXsrMzLTbp0OHDrYvI9Zl5MiRDh2HhA8AgMWVSfVaF0ds2bJFo0aN0s6dO7Vx40ZduHBBXbp0UV5ent1+w4cPV3Z2tm2ZPXu2Q8ehpQ8AgIU7Wvrvv/++3esVK1aoevXqysjI0O23325bX7FiRUVERFxzXFT4AACUgdzcXLslPz+/VO/LycmRJFWpUsVu/csvv6xq1aqpSZMmevjhh3X27FmH4qHCBwDAwpUVfnR0tN36adOmKTU19arvLSws1Lhx49S2bVs1adLEtv6ee+5RnTp1FBkZqa+//loPPfSQMjMztXbt2lLHRcIHAMDKhZflZWVlKSwszLbabDb/6VtHjRqlb7/9Vtu2bbNbP2LECNu/N23aVDVr1tQdd9yhAwcOqEGDBqUKi4QPAEAZCAsLs0v4f2b06NHasGGDtm7dqlq1al1131tuuUWStH//fhI+AACOcsekPcMwNGbMGK1bt06bN29WvXr1/vQ9e/bskSTVrFmz1Mch4QMAYOGOhD9q1CitWrVKb775pkJDQ3Xs2DFJUnh4uIKDg3XgwAGtWrVKd911l6pWraqvv/5a48eP1+23365mzZqV+jgkfAAA3GjJkiWSLt1c53LLly9XUlKSAgMD9eGHH2rhwoXKy8tTdHS0+vTpo8cee8yh45DwAQCwcFdL/2qio6O1ZcsWZ0KSRMIHAOAPXvzwHG68AwCAD6DCBwDAwpuflkfCBwDAwpsTPi19AAB8ABU+AAAWJrmgwvfQWXskfAAALGjpAwCAco0KHwAAKy++Dp+EDwCABS19AABQrlHhAwBg4c0VPgkfAAALk+nS4uwYnoiWPgAAPoAKHwAAi0sVvrMtfRcF42IkfAAArFzQ0vfUy/Jo6QMA4AOo8AEAsGCWPgAAPoBZ+gAAoFyjwgcAwMLPzyQ/P+dKdMPJ95cVKnwAAHwAFT4AABbefA6fhA+fN7RPOw3tc5uia1aRJH33wzHNSX9PH376X0lS4t/bqm/Xv6hZXC2FhQSrTsdJyj3zuztDhhc5+3u+0l/9UNs++69+y81Tw7o1NWboX9Uoppa7Q/NJ3jxL360t/aSkJPXq1avI+s2bN8tkMunUqVPXPSb4nqM/n9L0Z95UxyGz1Slxjj7ZvU8vzx2hRvUjJEnBQRW0acd/tWDF/7k5UnijOUvWKeOrA3rkwb5aNm+M/tI8RskzluuXE7nuDg1ehnP48Hnvf/KtNn76X/2Q9YsOHP5Zjy95W3ln8/WXJvUkSc+9slkLX9yoz7/50b2Bwuvk51/Qlp3/1T/u7arm8fVUq2ZV3df/DkVFVNWb//eZu8PzSdaWvrOLJyo3CX/NmjW66aabZDabVbduXc2bN89ue926dTVz5kwNHDhQlSpVUlRUlBYvXmy3j8lkUmBgoI4fP25b98svv8hsNjvcgunQoYNGjx6t0aNHKzw8XNWqVVNKSooMw7CLaeHChbbXmzZtkslksnU1kpKSbO2jK5ekpCTbcUwmk9auXWt3/JYtW8pkMmnz5s0OxY2r8/MzqfedrVUxOFCff3PQ3eHAyxUUFqqwsFCBFezPrgYGBuibvYfcFJVvK+l3sqOLJyoXCT8jI0P9+vXTgAED9M033yg1NVUpKSlasWKF3X5z5sxR8+bN9eWXX2rKlCkaO3asNm7caLdP9erVtXz5ctvr5cuX68Ybb7ymuF588UUFBARo165dWrRokebPn6+0tLRi9y0sLFRycrJCQkJs6xYtWqTs7GxlZ2erX79+6tevn+31okWLbPtFRUXphRdesL3etWuXfvnll6vGlp+fr9zcXLsFJYtvEKmsLfN0fPtCzX+4v+6dtFSZB4+5Oyx4uYrBZt0UG62Vb3ysX0/mqqCgUP+3dY/+uy9LJ0+dcXd48DJuT/gbNmxQSEiI3dK9e3e7febPn6877rhDKSkpio2NVVJSkkaPHq05c+bY7de2bVtNmTJFsbGxGjNmjPr27asFCxbY7TN06FClpaXJMAwZhqG0tDQNHTr0mmKPjo7WggULFBcXp0GDBmnMmDFFjmf14osvKj8/Xz179rStCw8PV0REhCIiIhQcHKzg4GDb6/DwcNt+PXr00JdffqlDhy5943/hhRf+NOZZs2YpPDzctkRHR1/TZ/QV3x86rtsHzVLn++Zq2Zptejb1XsXVi3B3WPABjzzYV5LUd8Rs3TkwVWvf3aFObZt5bJXo7ajwy1DHjh21Z88eu+XKKnnv3r1q27at3bq2bdvq+++/V0FBgW1dQkKC3T4JCQnau3ev3bpWrVqpcuXK+uijj/Txxx8rNDRUrVq1uqbYb731Vrv/sAkJCUVikqSzZ8/qscce0+zZsxUQ4PiFEYGBgbr33nuVlpam3NxcrVu3TkOGDLnqex5++GHl5OTYlqysLIeP60suXCzQwSO/6qvvsjRj8Vv69vufNHJAB3eHBR8QFVFVi2bcr/f+d6pef36Snvv3AyooKFBkjRvcHZpP8uZz+G6/LK9SpUqKiYmxW3fkyJEyPeaIESO0dOlSGYahESNGlOmxpEunGuLi4nT33XdrzZo11zTGiBEj1KlTJ9WoUUNdunRRtWrVrrq/2WyW2Wy+pmNB8jOZFBjo9v894EOCgwIVHBSo02d+1649+zXy3q7uDgleplz8RmvcuLG2b99ut2779u2KjY2Vv7+/bd3OnTvt9tm5c6caN25cZLx77rlHjzzyiK2lv2nTpmuK67PP7GfR7ty5Uw0bNrSLKTs7W0uWLNGWLVuu6RhWsbGxatiwoR555BGtX7/eqbFgb+qoHvrw0/8o69hvCq0YpL7d/qJ2rRuqz5hnJUnVq4aqetUw1Y++9CXrpphInT57TkeO/aZTuWfdGTq8wK4938swDNWOrKafjp3UkpfeV+2oaure8do6j3COSS64Dl+eWeKXi4SfnJysm2++WTNnzlT//v21Y8cOPfPMM3r22Wft9tu+fbtmz56tXr16aePGjXr99df1zjvvFBkvJCREzz33nAoLCxUaGlpk+65duzRkyBBt2rRJUVFRJcZ1+PBhTZgwQf/4xz/0xRdf6Omnny5y9cDixYvVp08ftWzZ8ho//R+efPJJbdu2TR07dlROTo7T4+GSajeEaEnqENWoFqbcM+f0n/0/qc+YZ7V513eSpPt636YpI+6y7f/u0vGSpH9Of0mvbODSKTgn7+w5LX35//TLiVyFhgTr9ltv0v0D71RAgP+fvxkux5323KxVq1ZavXq1pk6dqpkzZ6pmzZqaMWOG7dI1q+TkZO3evVvTp09XWFiY5s+fr65di2+L9e3bt8TjnT17VpmZmbpw4cJV4xoyZIh+//13tWnTRv7+/ho7dmyRUwSFhYV64oknSvdB/0SbNm3Upk0bl4yFPzz4+Kqrbn9y6bt6cum71yka+JqO/9NUHf+nqbvDgA8wGZdfOF6O1a1bV+PGjdO4ceOuy/E6dOigFi1a2F1n78lyc3MVHh4uc9PhMvkHujsceLnNbzzu7hDgA/JO5+qOlnWUk5OjsLAwp8ay/o5s/sjb8g+q5NRYBefy9NW/7nZJXK5ULip8AACuB29u6bv9sjwAAFD2vKbC//HHH6/r8bilLQB4H29+Wp7XJHwAAJxFSx8AAJRrVPgAAFjQ0gcAwBe44l74npnvaekDAOALqPABALCgpQ8AgA9glj4AACjXqPABALCgpQ8AgA+gpQ8AAMo1KnwAACxo6QMA4AO8OeHT0gcAwAdQ4QMAYOHNk/ZI+AAAWNDSBwAA5RoVPgAAFt7c0qfCBwDAwtrSd3ZxxKxZs3TzzTcrNDRU1atXV69evZSZmWm3z7lz5zRq1ChVrVpVISEh6tOnj44fP+7QcUj4AAC40ZYtWzRq1Cjt3LlTGzdu1IULF9SlSxfl5eXZ9hk/frzefvttvf7669qyZYuOHj2q3r17O3QcWvoAAFiY5IKWvuWfubm5duvNZrPMZnOR/d9//3271ytWrFD16tWVkZGh22+/XTk5OUpPT9eqVavUqVMnSdLy5cvVuHFj7dy5U7feemup4qLCBwDAws9kcskiSdHR0QoPD7cts2bNKlUMOTk5kqQqVapIkjIyMnThwgV17tzZtk+jRo1Uu3Zt7dixo9SfjQofAIAykJWVpbCwMNvr4qr7KxUWFmrcuHFq27atmjRpIkk6duyYAgMDVblyZbt9a9SooWPHjpU6HhI+AAAWrpylHxYWZpfwS2PUqFH69ttvtW3bNueCKAYJHwAAC3feeGf06NHasGGDtm7dqlq1atnWR0RE6Pz58zp16pRdlX/8+HFFRESUenzO4QMA4EaGYWj06NFat26dPvroI9WrV89ue+vWrVWhQgVt2rTJti4zM1OHDx9WQkJCqY9DhQ8AgIWf6dLi7BiOGDVqlFatWqU333xToaGhtvPy4eHhCg4OVnh4uIYNG6YJEyaoSpUqCgsL05gxY5SQkFDqGfoSCR8AgD+YXHAvfAffvmTJEklShw4d7NYvX75cSUlJkqQFCxbIz89Pffr0UX5+vrp27apnn33WoeOQ8AEAcCPDMP50n6CgIC1evFiLFy++5uOQ8AEAsPDme+mT8AEAsDBZ/jg7hidilj4AAD6ACh8AAAt3zNK/Xkj4AABYuPPGO2WNlj4AAD6ACh8AAAufn6X/1ltvlXrAHj16XHMwAAC40+WPt3VmDE9UqoTfq1evUg1mMplUUFDgTDwAAKAMlCrhFxYWlnUcAAC4nc+39Ety7tw5BQUFuSoWAADciln6lykoKNDMmTMVFRWlkJAQ/fDDD5KklJQUpaenuzxAAADgPIcT/hNPPKEVK1Zo9uzZCgwMtK1v0qSJ0tLSXBocAADXk7Wl7+ziiRxO+CtXrtQLL7ygQYMGyd/f37a+efPm+u6771waHAAA15N1lr6ziydyOOH/9NNPiomJKbK+sLBQFy5ccElQAADAtRxO+PHx8frkk0+KrH/jjTfUsmVLlwQFAIA7mFy0eCKHZ+lPnTpViYmJ+umnn1RYWKi1a9cqMzNTK1eu1IYNG8oiRgAArgtm6V+mZ8+eevvtt/Xhhx+qUqVKmjp1qvbu3au3335bd955Z1nECAAAnHRN1+Hfdttt2rhxo6tjAQDArXg8bjF2796tvXv3Srp0Xr9169YuCwoAAHfw5pa+wwn/yJEjGjhwoLZv367KlStLkk6dOqX/+Z//0auvvqpatWq5OkYAAOAkh8/h33///bpw4YL27t2rkydP6uTJk9q7d68KCwt1//33l0WMAABcN9540x3pGir8LVu26NNPP1VcXJxtXVxcnJ5++mnddtttLg0OAIDryZtb+g5X+NHR0cXeYKegoECRkZEuCQoAALiWwwl/zpw5GjNmjHbv3m1bt3v3bo0dO1Zz5851aXAAAFxP1ln6zi6eqFQt/RtuuMGuRZGXl6dbbrlFAQGX3n7x4kUFBARo6NCh6tWrV5kECgBAWfPmln6pEv7ChQvLOAwAAFCWSpXwExMTyzoOAADczhX3wvfM+t6JG+9I0rlz53T+/Hm7dWFhYU4FBACAu7ji8bZe83jcvLw8jR49WtWrV1elSpV0ww032C0AAMDzOJzwJ0+erI8++khLliyR2WxWWlqapk+frsjISK1cubIsYgQA4Lpw9qY7nnzzHYdb+m+//bZWrlypDh066L777tNtt92mmJgY1alTRy+//LIGDRpUFnECAFDmvHmWvsMV/smTJ1W/fn1Jl87Xnzx5UpLUrl07bd261bXRAQAAl3A44devX18HDx6UJDVq1EirV6+WdKnytz5MBwCA8sibW/oOJ/z77rtPX331lSRpypQpWrx4sYKCgjR+/HhNmjTJ5QECAHC9WGfpO7t4IofP4Y8fP9727507d9Z3332njIwMxcTEqFmzZi4NDgAAuIZT1+FLUp06dVSnTh1XxAIAgFu5oiXvoQV+6RL+U089VeoBH3zwwWsOBgAAd/LmWfqlSvgLFiwo1WAmk4mE7+EOb57L3RBR5o6c/N3dIcAHBMrs7hDKlVIlfOusfAAAvJmfrmE2ezFjeCKnz+EDAOAtvLml76lfRAAAgAtR4QMAYGEySX6+PEsfAABf4OeChO/s+8sKLX0AAHzANSX8Tz75RIMHD1ZCQoJ++uknSdJLL72kbdu2uTQ4AACuJ+ukPWcXT+Rwwl+zZo26du2q4OBgffnll8rPz5ck5eTk6F//+pfLAwQA4HqxtvSdXTyRwwn/8ccf13PPPaelS5eqQoUKtvVt27bVF1984dLgAACAazg8aS8zM1O33357kfXh4eE6deqUK2ICAMAtvPle+g5X+BEREdq/f3+R9du2bVP9+vVdEhQAAO7gzY/HdTjhDx8+XGPHjtVnn30mk8mko0eP6uWXX9bEiRP1wAMPlEWMAADASQ639KdMmaLCwkLdcccdOnv2rG6//XaZzWZNnDhRY8aMKYsYAQC4LriX/mVMJpMeffRRTZo0Sfv379eZM2cUHx+vkJCQsogPAIDrxpvP4V/znfYCAwMVHx/vylgAAEAZcTjhd+zY8ao3Ffjoo4+cCggAAHfxk/OT7vzkmSW+w6caWrRooebNm9uW+Ph4nT9/Xl988YWaNm1aFjECAHBdWFv6zi6O2rp1q+6++25FRkbKZDJp/fr1dtuTkpKK3M2vW7duDh3D4Qp/wYIFxa5PTU3VmTNnHB0OAACfl5eXp+bNm2vo0KHq3bt3sft069ZNy5cvt702m80OHcNlT8sbPHiw2rRpo7lz57pqSAAArit3PS2ve/fu6t69+1X3MZvNioiIuMaoXHj1wI4dOxQUFOSq4QAAuO5MJudvvmNt6efm5tot1mfPXKvNmzerevXqiouL0wMPPKATJ0449H6HK/wrWw2GYSg7O1u7d+9WSkqKo8MBAOCVoqOj7V5PmzZNqamp1zRWt27d1Lt3b9WrV08HDhzQI488ou7du2vHjh3y9/cv1RgOJ/zw8HC7135+foqLi9OMGTPUpUsXR4cDAMBjuPI6/KysLIWFhdnWO3rO/XIDBgyw/XvTpk3VrFkzNWjQQJs3b9Ydd9xRqjEcSvgFBQW677771LRpU91www2ORQsAgIdz5Tn8sLAwu4TvSvXr11e1atW0f//+Uid8h87h+/v7q0uXLjwVDwAANzpy5IhOnDihmjVrlvo9Drf0mzRpoh9++EH16tVz9K0AAHg0k+WPs2M46syZM3ZPoj148KD27NmjKlWqqEqVKpo+fbr69OmjiIgIHThwQJMnT1ZMTIy6du1a6mM4PEv/8ccf18SJE7VhwwZlZ2cXmYUIAEB5ZW3pO7s4avfu3WrZsqVatmwpSZowYYJatmypqVOnyt/fX19//bV69Oih2NhYDRs2TK1bt9Ynn3zi0LyAUlf4M2bMUHJysu666y5JUo8ePexusWsYhkwmkwoKCkp9cAAAIHXo0EGGYZS4/YMPPnD6GKVO+NOnT9fIkSP18ccfO31QAAA8kbtuvHM9lDrhW795tG/fvsyCAQDAnaz3qXd2DE/k0Dl8T/0QAADg6hyapR8bG/unSf/kyZNOBQQAgLvQ0reYPn16kTvtAQDgLVx5pz1P41DCHzBggKpXr15WsQAAgDJS6oTP+XsAgLezPvHO2TE8kcOz9AEA8Facw5dUWFhYlnEAAIAy5PC99AEA8FoumLTn5K34ywwJHwAACz+Z5Odkxnb2/WXF4YfnAACA8ocKHwAAC67DBwDAB3jzLH1a+gAA+AAqfAAALLjxDgAAPsCbz+HT0gcAwAdQ4QMAYOEnF7T0PfQ6fBI+AAAWtPQBAEC5RoUPAICFn5yvhD21kibhAwBgYTKZZHKyJ+/s+8uKp34RAQAALkSFDwCAhUnOP93WM+t7Ej4AADbefKc9WvoAAPgAKnwAAC7jmfW580j4AABYcOMdAABQrlHhAwBg4c3X4ZPwAQCw8OY77XlqXAAAwIWo8AEAsKClDwCAD/DmO+3R0gcAwAdQ4QMAYEFLHwAAH8AsfQAAUK5R4QMAYEFLHwAAH8AsfQAAUK5R4QMAYOHNT8sj4QMAYOEnk/ycbMo7+/6yQksfAAAfQIUPXGH+8g+04eOv9P2h4woyV1CbZvWVOrqnGtat4e7Q4IWO/5qjBenvaNvnmTqXf17RkdX0eHI/3RQb7e7QfBItfcCHfPrFft3//25Xy/g6ulhQoJnPvq3eY57RztWPqVKw2d3hwYvknD6rIRMW6+ZmDbTk8WG6oXKIDv/0i8JCgt0dms8yWf44O4Yn8qiEv2PHDrVr107dunXTO++84+5w4KPeeHqU3etnpw1Wwy4Pa8/eLLVtFeOmqOCNlq3erIhqlfX4xP62dbUiqrgxIngzjzqHn56erjFjxmjr1q06evSou8MBJEm5Z85Jkm4Iq+jmSOBtNu/8j+Jja2nC4y+pfb9U/b9/LtAb737m7rB8mrWl7+ziiTwm4Z85c0avvfaaHnjgAf31r3/VihUrbNs2b94sk8mkZs2a2b3nzTfflMlkUocOHWzrOnTooHHjxtleZ2ZmqkKFCmrRooXde61jXr5UrlzZtr2wsFAzZsxQrVq1ZDab1aJFC73//vu27T/++KNMJpP27NljW5eSkiKTyaSFCxfaHSs1NbXIsXr16mW3z5o1a3TTTTfJbDarbt26mjdvnt32Tp06qUqVKjKbzWrcuLFeeumlEn+WkpSfn6/c3Fy7BY4rLCzUw/Pf0C3N6ys+JtLd4cDLHMk+qdUbdqhOZDU996/h6ve3BP17yXq9uXG3u0PzWSbLLH1nFk9t6XtMwl+9erUaNWqkuLg4DR48WMuWLZNhGHb7nDx5Ujt37rS9fv755xUVFXXVcSdNmqSgoKAi661jZ2ZmKjs7u0iSXrRokebNm6e5c+fq66+/VteuXdWjRw99//33xR7nyJEjWrhwoYKDiz/3dtNNNyk7O1vZ2dnq16+f3baMjAz169dPAwYM0DfffKPU1FSlpKTYfekZNWqUtm3bpn379mnkyJFKTEzUoUOHSvzcs2bNUnh4uG2JjmYC0LWYOHu19h7IVvoT97k7FHihQsNQ45gojR3aXY1jovT/7rpVfbrfotXv7HB3aPBCHpPw09PTNXjwYElSt27dlJOToy1bttjtM3ToUC1dulSSdPjwYWVkZKhHjx4ljvnxxx/r008/1f33319k24ULFyRJUVFRioiIUHh4uN32uXPn6qGHHtKAAQMUFxenJ598Ui1atCjyxcDq0UcfVf/+/VW9evUi2/Lz8xUcHKyIiAhFREQU+VIwf/583XHHHUpJSVFsbKySkpI0evRozZkzx7ZPnz59FB8frzp16qhRo0aSpIsXL5b42R9++GHl5OTYlqysrBL3RfEmzV6tDz75Vm8veVBRNW5wdzjwQjdWCVWDOvZXf9SPrq5jP59yT0CgpV/WMjMztWvXLg0cOFCSFBAQoP79+ys9Pd1uv8TERK1fv165ublKS0vT4MGDFRgYWOyYhmEoOTlZ06ZNK5LMJSk3N1d+fn7FVuS5ubk6evSo2rZta7e+bdu22rt3b5H9v/jiC61bt04zZ84sNpYTJ04oLCys+A8vae/evcUe6/vvv1dBQYFtXffu3WU2m/X3v/9dy5YtU4MGDUoc02w2KywszG5B6RiGoUmzV+udzV/prSUPqk5UNXeHBC/VIr6ufsz6xW7djz/9qprV+YLpLiT8Mpaenq6LFy8qMjJSAQEBCggI0JIlS7RmzRrl5OTY9qtataq6du2qlStXatmyZRo+fHiJY65cuVJ5eXkaOXJksduPHj2qGjVqyM/P+R9BcnKyJk6cqJo1axa7/YcfflC9evWcPk5aWpoyMjI0efJkPfbYY/rll1/+/E1w2MQnV2v1e59r6cwkhVQM0vFfc3X811z9fu68u0ODlxnS+3Z9/d0hLX1lkw7/9Kve+ehLrXl3pwb0+B93hwYv5PbL8i5evKiVK1dq3rx56tKli922Xr166ZVXXrG1sCXpH//4h+6++261aNHCbv3lzp49q0cffVTPPPOMKlSoUOw+n3/+uVq2bFnstrCwMEVGRmr79u1q3769bf327dvVpk0bu33feust7du3r8TLCM+dO6ddu3bp3nvvLXa7JDVu3Fjbt2+3W7d9+3bFxsbK39/fti4qKkpRUVFq0qSJFi1apC1btqhv374ljotrs2zNJ5Kkv41cZLd+8dTBuufuW90RErxUk7hoLZyaqIXL39NzL3+oqIgqmjyyp/7WqZW7Q/NZXIdfhjZs2KDffvtNw4YNK9J679Onj9LT0+3OZbdv317Tp09XQkJCiWOuWrVKrVu3LjITXrp0NUBaWppWrVql1157rcQxJk2apGnTpqlBgwZq0aKFli9frj179ujll1+222/27Nl6+umnVbFi0Uu2zpw5oxkzZkiS2rVrp2PHjkmSfv/9d+Xn5ysnJ0fh4eFKTk7WzTffrJkzZ6p///7asWOHnnnmGT377LOSpIMHD9q+oBiGoZUrV+r06dNq2rRpifHj2v32+TPuDgE+pP2t8Wp/a7y7w4CFn+nS4uwYjtq6davmzJmjjIwMZWdna926dXY5zDAMTZs2TUuXLtWpU6fUtm1bLVmyRA0bNiz1Mdye8NPT09W5c+diz7P36dNHs2fP1tdff223fvz48Vcd8+zZs0Uua7PauHGjli5dqueff/6q1fGDDz6onJwcJScn6+eff1Z8fLzeeuutIj/cmJgYJSYmFjvG3LlzbV9WYmKK3rBl7NixWrFihVq1aqXVq1dr6tSpmjlzpmrWrKkZM2YoKSlJ0qUuyIIFC/Sf//xHhmGoUaNGev311xUXF3fVnwMAoHzIy8tT8+bNNXToUPXu3bvI9tmzZ+upp57Siy++qHr16iklJUVdu3bVf//732KvRCuOybjy2je4TGpqqt0/L7d+/XqtX7/e7tK7spSbm6vw8HAdP5HDBD6UuSMnf3d3CPABp0/nqlVMhHJynP+9Zv0d+dbnB1UpJNSpsfLOnFaPm+tdc1wmk8muwjcMQ5GRkbb5YpKUk5OjGjVqaMWKFRowYECpxvWISXveKiQkRCEhIcVuCwoKKrarAQBwH1fO0r/y5mf5+fnXFNPBgwd17Ngxde7c2bYuPDxct9xyi3bsKP09G9ze0vdm1m9ixenWrZu6det2HaMBAFxPV97wbNq0acV2fP+Mdf5XjRr292yoUaOGbVtpkPABALAwyflZ9tZ3Z2Vl2bX0zWb3Pm2ThA8AgIUrZ+m76qZnERERkqTjx4/b3e/l+PHjRZ4Tc9W4nI4EAACUmXr16ikiIkKbNm2yrcvNzdVnn3121UvUr0SFDwCAhbtuvHPmzBnt37/f9vrgwYPas2ePqlSpotq1a2vcuHF6/PHH1bBhQ9tleZGRkcXeb6YkJHwAACxccS/8a3n/7t271bFjR9vrCRMmSLr0DJkVK1Zo8uTJysvL04gRI3Tq1Cm1a9dO77//fqmvwZdI+AAAuF2HDh2KPBL+ciaTSTNmzLDdvfVakPABALAwSU7fCd8z76RPwgcAwMZPJvk52dP389CUzyx9AAB8ABU+AAAWtPQBAPAFXpzxaekDAOADqPABALBw1413rgcSPgAAVi648Y6H5nta+gAA+AIqfAAALLx4zh4JHwAAGy/O+LT0AQDwAVT4AABYMEsfAAAf4K7H414PtPQBAPABVPgAAFh48Zw9KnwAAHwBFT4AAFZeXOKT8AEAsPDmWfq09AEA8AFU+AAAWHjzZXkkfAAALLz4FD4tfQAAfAEVPgAAVl5c4pPwAQCwYJY+AAAo16jwAQCwYJY+AAA+wItP4dPSBwDAF1DhAwBg5cUlPgkfAAALZukDAIByjQofAAALZukDAOADvPgUPi19AAB8ARU+AABWXlzik/ABALBglj4AACjXqPABALBglj4AAD7Ai0/h09IHAMAXUOEDAGDlxSU+CR8AAAtm6QMAgHKNCh8AACsXzNL30AKfhA8AgJUXn8KnpQ8AgC+gwgcAwMqLS3wSPgAAFszSBwAA5RoVPgAAFtxLHwAAH+DFp/Bp6QMA4Auo8AEAsPLiEp+EDwCABbP0AQBAuUbCBwDAwqQ/Zupf8+LgMVNTU2UymeyWRo0aufyz0dIHAMDCXafwb7rpJn344Ye21wEBrk/PJHwAAMpAbm6u3Wuz2Syz2VzsvgEBAYqIiCjTeGjpAwBg4XQ7/7Ib90RHRys8PNy2zJo1q8Tjfv/994qMjFT9+vU1aNAgHT582OWfjQofAAAb1zX1s7KyFBYWZltbUnV/yy23aMWKFYqLi1N2dramT5+u2267Td9++61CQ0OdjOUPJHwfYRiGJOn0FS0moCycPv27u0OADzhz+rSkP36/eZqwsDC7hF+S7t272/69WbNmuuWWW1SnTh2tXr1aw4YNc1k8JHwfcdryP0ZMvWg3RwIArnX69GmFh4e7ZCxPuJd+5cqVFRsbq/379zs30BVI+D4iMjJSWVlZCg0NlclTn+zgYXJzcxUdHV2kLQe4Gn/Xro1hGDp9+rQiIyNdNqYn3GjvzJkzOnDggO69914nR7JHwvcRfn5+qlWrlrvDKJdK25YDnMXfNce5qrJ3p4kTJ+ruu+9WnTp1dPToUU2bNk3+/v4aOHCgS49DwgcAwMIdLf0jR45o4MCBOnHihG688Ua1a9dOO3fu1I033uhcIFcg4QMAYOGOe+m/+uqrTh2vtLgOHyiB2WzWtGnTSryUBnAV/q7hejAZnno9AwAA10lubq7Cw8O1L+tXhTo5j+J0bq5io6spJyfHo+Zk0NIHAMDCE2bplxVa+gAA+AAqfAAALDzhxjtlhYQPAICFO2bpXy+09OFWSUlJ6tWrV5H1mzdvlslk0qlTp657TADgjUj4AHzOjh075O/vr7/+9a/uDgWexuSixQOR8FFurFmzRjfddJPMZrPq1q2refPm2W2vW7euZs6cqYEDB6pSpUqKiorS4sWL7fYxmUwKDAzU8ePHbet++eUXmc1mh58x0KFDB40ePVqjR49WeHi4qlWrppSUFLsnd9WtW1cLFy60vd60aZNMJpOtq5GUlCSTyVTskpSUZDuOyWTS2rVr7Y7fsmVLmUwmbd682aG4IaWnp2vMmDHaunWrjh496u5w4EG8ON+T8FE+ZGRkqF+/fhowYIC++eYbpaamKiUlRStWrLDbb86cOWrevLm+/PJLTZkyRWPHjtXGjRvt9qlevbqWL19ue718+fJrvoXliy++qICAAO3atUuLFi3S/PnzlZaWVuy+hYWFSk5OVkhIiG3dokWLlJ2drezsbPXr10/9+vWzvV60aJFtv6ioKL3wwgu217t27dIvv/xyTTH7ujNnzui1117TAw88oL/+9a92f4esp5KaNWtm954333xTJpNJHTp0sK3r0KGDxo0bZ3udmZmpChUqqEWLFnbvtY55+VK5cmXb9sLCQs2YMUO1atWS2WxWixYt9P7779u2//jjjzKZTNqzZ49tXUpKikwmk92XSUlKTU0tcqwrT5n92RfnTp06qUqVKjKbzWrcuLFeeumlEn+WKF9I+HC7DRs2KCQkxG65/PnQkjR//nzdcccdSklJUWxsrJKSkjR69GjNmTPHbr+2bdtqypQpio2N1ZgxY9S3b18tWLDAbp+hQ4cqLS1NhmHIMAylpaVp6NCh1xR7dHS0FixYoLi4OA0aNEhjxowpcjyrF198Ufn5+erZs6dtXXh4uCIiIhQREaHg4GAFBwfbXl/+UJAePXroyy+/1KFDhyRJL7zwwjXH7OtWr16tRo0aKS4uToMHD9ayZcuKPE/95MmT2rlzp+31888/r6ioqKuOO2nSJAUFBRVZbx07MzNT2dnZRZL0okWLNG/ePM2dO1dff/21unbtqh49euj7778v9jhHjhzRwoULFRwcXOz2m266ye5L5OVK88V51KhR2rZtm/bt26eRI0cqMTHR9vfOF1hn6Tu7eCISPtyuY8eO2rNnj91yZZW8d+9etW3b1m5d27Zt9f3336ugoMC2LiEhwW6fhIQE7d27125dq1atVLlyZX300Uf6+OOPFRoaqlatWl1T7LfeeqvdqYCEhIQiMUnS2bNn9dhjj2n27NkKCHD84pjAwEDde++9SktLU25urtatW6chQ4ZcU8y+Lj09XYMHD5YkdevWTTk5OdqyZYvdPkOHDtXSpUslSYcPH1ZGRoZ69OhR4pgff/yxPv30U91///1Ftl24cEHSpS7NlV/kJGnu3Ll66KGHNGDAAMXFxenJJ59UixYtinwxsHr00UfVv39/Va9evci2/Px8uy+NV34pKM0X5z59+ig+Pl516tRRo0aNJEkXL14s8bN7H5PTfzy1qc9leXC7SpUqKSYmxm7dkSNHyvSYI0aM0NKlS2UYhkaMGFGmx5IunWqIi4vT3XffrTVr1lzTGCNGjFCnTp1Uo0YNdenSRdWqVXNxlN4vMzNTu3bt0rp16yRJAQEB6t+/v9LT0+3a9YmJiWrTpo0WLFigtLQ0DR48uMiXOCvDMJScnKxp06bpxIkTRbbn5ubKz8+v2Io8NzdXR48eLfbL7FdffVVk/y+++ELr1q1TZmamPvzwwyLbT5w4cdVbue7du9euw2Q91sKFC1VQUCB/f39JUvfu3fXRRx/J399fy5YtU4MGDUocE+UHFT7KhcaNG2v79u1267Zv367Y2FjbLylJdm1Y6+vGjRsXGe+ee+7Rhx9+qA8//FD33HPPNcf12WefFTlew4YN7WLKzs7WvHnzipwrdVRsbKwaNmyoRx55RMOHD3dqLF+Vnp6uixcvKjIyUgEBAQoICNCSJUu0Zs0a5eTk2ParWrWqunbtqpUrV2rZsmVX/XmvXLlSeXl5GjlyZLHbjx49qho1asjPz/lft8nJyZo4caJq1qxZ7PYffvhB9erVc/o4aWlpysjI0OTJk/XYY4/51HwRWvqAmyUnJ2vTpk2aOXOm9u3bpxdffFHPPPOMJk6caLff9u3bNXv2bO3bt0+LFy/W66+/rrFjxxYZLyQkRM8995yWLFmi0NDQItt37dqlRo0a6aeffrpqXIcPH9aECROUmZmpV155RU8//XSR4y1evFh///vf1bJly2v45PaefPJJpaamqmPHjk6P5WsuXryolStXat68eXanj7766itFRkbqlVdesdv/H//4hx555BHVr1/f1tq+0tmzZ/Xoo4/qySefVIUKFYrd5/PPPy/xv31YWJgiIyOL/TIbHx9vt+6tt97Svn37ivydtzp37px27dql2267rdjtUum/OEdFRalJkyZKTU1VXl5ekVMeKJ9o6aNcaNWqlVavXq2pU6dq5syZqlmzpmbMmGG7dM0qOTlZu3fv1vTp0xUWFqb58+era9euxY7Zt2/fEo939uxZZWZm2s6/lmTIkCH6/fff1aZNG/n7+2vs2LFFThEUFhbqiSeeKN0H/RNt2rRRmzZtXDKWr9mwYYN+++03DRs2rMh59D59+ig9Pd3uXHb79u01ffr0IvNCLrdq1Sq1bt262JtHnTlzRmlpaVq1apVee+21EseYNGmSpk2bpgYNGqhFixZavny59uzZo5dfftluv9mzZ+vpp59WxYoViz3WjBkzJEnt2rXTsWPHJEm///678vPzlZOTo/DwcCUnJ+vmm2/WzJkz1b9/f+3YsUPPPPOMnn32WUnSwYMHbV9QDMPQypUrdfr0aTVt2rTE+FGOGICXqFOnjrFgwYLrdrz27dsbY8eOvW7Hg3P+9re/GXfddVex2z777DNDkrFo0SJDkvHbb78V2Wfs2LFG+/btba/bt29vmEwm4/PPP7etmzZtmtG8eXPDMAxj7dq1Rnx8vLF06VK7cZYvX26Eh4fbXhcUFBipqalGVFSUUaFCBaN58+bGe++9Z9t+8OBBQ5LRvHlzo6CgwLb+8r/v06ZNMySVuCQmJtre98Ybbxjx8fFGhQoVjNq1axtz5syxbdu3b59x6623GqGhoUZISIjxl7/8xVi7dm1JP1KvkpOTY0gyDh07afx29qJTy6FjJw1JRk5Ojrs/lh2TYVxxPQpQTtWtW1fjxo2zuza6LHXo0OGqs6mB6yU1NdXun5dbv3691q9fX+SeFbCXm5ur8PBwHT72m9PPsM/NzVXtiBuUk5Pj9FiuREsfAMq5y2/mdKWgoKAipzDgm6jwAQA+z1rhZx13TYUfXYMKHwAAj+WK2+Z46FV5XJYHAIAvoMIHAMDKi0t8Ej4AABZ/3A/fuTE8ES19AAB8AAkf8EFJSUl2d4e78tnu14v1WfGnTp0qcR+TyaT169eXeszU1NQiz6R3VHHPoIdv4F76AMpcUlKSTCaTTCaTAgMDFRMToxkzZlyXR5OuXbtWM2fOLNW+pUnSQHllctHiiTiHD3iQbt26afny5crPz9e7776rUaNGqUKFCnr44YeL7Hv+/HkFBga65LhVqlRxyTgAPBcVPuBBzGazIiIiVKdOHT3wwAPq3Lmz3nrrLUl/tOGfeOIJRUZGKi4uTpKUlZWlfv36qXLlyqpSpYp69uypH3/80TZmQUGBJkyYoMqVK6tq1aqaPHmyrrzf1pUt/fz8fD300EOKjo6W2WxWTEyM0tPT9eOPP9qe1HfDDTfIZDLZHmBUWFioWbNmqV69egoODlbz5s31xhtv2B3n3XffVWxsrIKDg9WxY0e7OEvroYceUmxsrCpWrKj69esrJSWl2IccPf/884qOjlbFihXVr18/u8ffSpceAdu4cWMFBQWpUaNGtgfIwMd5cYlPhQ94sODgYJ04ccL2etOmTQoLC9PGjRslSRcuXFDXrl2VkJCgTz75RAEBAXr88cfVrVs3ff311woMDNS8efO0YsUKLVu2TI0bN9a8efO0bt06derUqcTjDhkyRDt27NBTTz2l5s2b6+DBg/r1118VHR2tNWvWqE+fPsrMzFRYWJiCg4MlSbNmzdL//u//6rnnnlPDhg21detWDR48WDfeeKPat2+vrKws9e7dW6NGjdKIESO0e/duJScnO/wzCQ0N1YoVKxQZGalvvvlGw4cPV2hoqCZPnmzbZ//+/Vq9erXefvtt5ebmatiwYfrnP/9pewLdyy+/rKlTp+qZZ55Ry5Yt9eWXX2r48OGqVKmSEhMTHY4J3sObZ+nztDzAQyQmJho9e/Y0DMMwCgsLjY0bNxpms9mYOHGibXuNGjWM/Px823teeuklIy4uzigsLLSty8/PN4KDg40PPvjAMAzDqFmzpjF79mzb9gsXLhi1atWyHcsw7J/8l5mZaUgyNm7cWGycH3/8cZEnyp07d86oWLGi8emnn9rtO2zYMGPgwIGGYRjGww8/bMTHx9ttf+ihh0p8Op2VJGPdunUlbp8zZ47RunVr2+tp06YZ/v7+xpEjR2zr3nvvPcPPz8/Izs42DMMwGjRoYKxatcpunJkzZxoJCQmGYfzxhLovv/yyxOPCu1iflnfs1xzj7HnDqeXYrzke+bQ8KnzAg2zYsEEhISG6cOGCCgsLdc8999g9Aa1p06Z25+2/+uor7d+/X6GhoXbjnDt3TgcOHFBOTo6ys7N1yy232LYFBAToL3/5S5G2vtWePXvk7++v9u3blzru/fv36+zZs7rzzjvt1p8/f14tW7aUJO3du9cuDklXfdZ8SV577TU99dRTOnDggM6cOaOLFy8WuV957dq1FRUVZXecwsJCZWZmKjQ0VAcOHNCwYcM0fPhw2z4XL17kITPQ6dO5Ts+yP3061zXBuBgJH/AgHTt21JIlSxQYGKjIyEgFBNj/L1qpUiW712fOnFHr1q1trerL3XjjjdcUg7VF74gzZ85Ikt555x27RCtdmpfgKjt27NCgQYM0ffp0de3aVeHh4Xr11Vc1b948h2NdunRpkS8g/v7+LosV5UtgYKAiIiLUsF60S8aLiIhw2aRaVyHhAx6kUqVKiomJKfX+rVq10muvvabq1auX+FSumjVr6rPPPtPtt98u6VIlm5GRoVatWhW7f9OmTVVYWKgtW7aoc+fORbZbf4kVFBTY1sXHx8tsNuvw4cMldgYaN25sm4BotXPnzj//kJf59NNPVadOHT366KO2dYcOHSqy3+HDh3X06FFFRkbajuPn56e4uDjVqFFDkZGR+uGHHzRo0CCHjg/vFRQUpIMHD+r8+fMuGS8wMFBBQUEuGctVSPhAOTZo0CDNmTNHPXv21IwZM1SrVi0dOnRIa9eu1eTJk1WrVi2NHTtW//73v9WwYUM1atRI8+fPv+o19HXr1lViYqKGDh1qm7R36NAh/fzzz+rXr5/q1Kkjk8mkDRs26K677lJwcLBCQ0M1ceJEjR8/XoWFhWrXrp1ycnK0fft2hYWFKTExUSNHjtS8efM0adIk3X///crIyNCKFSsc+rwNGzbU4cOH9eqrr+rmm2/WO++8o3Xr1hXZLygoSImJiZo7d65yc3P14IMPql+/foqIiJAkTZ8+XQ8++KDCw8PVrVs35efna/fu3frtt980YcIEh2KC9wgKCvK4JO1KXJYHlGMVK1bU1q1bVbt2bfXu3VuNGzfWsGHDdO7cOVvFn5ycrHvvvVeJiYlKSEhQaGio/v73v1913CVLlqhv37765z//qUaNGmn48OHKy8uTJEVFRWn69OmaMmWKatSoodGjR0uSZs6cqZSUFM2aNUuNGzdWt27d9M4776hevXqSLp1XX7NmjdavX6/mzZvrueee07/+9S+HPm+PHj00fvx4jR49Wi1atNCnn36qlJSUIvvFxMSod+/euuuuu9SlSxc1a9bM7rK7+++/X2lpaVq+fLmaNm2q9u3ba8WKFbZYAW9kMkqauQMAALwGFT4AAD6AhA8AgA8g4QMA4ANI+AAA+AASPgAAPoCEDwCADyDhAwDgA0j4AAD4ABI+AAA+gIQPAIAPIOEDAOAD/j+YMFUBFJSCjwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def validate_model(model, dataloader):\n",
    "    model = MultiBranchECGNet(num_channels=8, num_classes=2)\n",
    "    model.load_state_dict(torch.load(\"model_weights.pth\", weights_only=True))\n",
    "    model.eval()  # Переводим модель в режим оценки\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():  # Отключаем градиенты для валидации\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)  # Предсказания с максимальной вероятностью\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    # Преобразуем в numpy массивы\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    # all_labels = np.argmax(all_labels, axis=1)\n",
    "\n",
    "    # Считаем accuracy\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    print(f\"Validation recall: {recall:.4f}\")\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Validation accuracy: {accuracy:.4f}\")\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    print(f\"Validation precision: {precision:.4f}\")\n",
    "\n",
    "    class_names = [\"Норм. ритм\", \"Амилоидоз\"]\n",
    "\n",
    "    print(\"\\n clasification report:\\n\", classification_report(all_labels, all_preds))\n",
    "\n",
    "    print(\"Матрица несоответствий для тестовой выборки метода ЛДА:\\n\")\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    disp = ConfusionMatrixDisplay(\n",
    "        confusion_matrix(all_labels, all_preds), display_labels=class_names\n",
    "    )\n",
    "    disp.plot(cmap=\"Blues\", ax=ax)\n",
    "\n",
    "    Logger.current_logger().report_confusion_matrix(\n",
    "        title=\"Confusion Matrix\",\n",
    "        series=\"Validation Results\",\n",
    "        matrix=confusion_matrix(all_labels, all_preds),\n",
    "        yaxis_reversed=True,\n",
    "        xaxis=\"Predicted\",\n",
    "        yaxis=\"Expected\",\n",
    "        xlabels=class_names,\n",
    "        ylabels=class_names,\n",
    "    )\n",
    "\n",
    "    return recall\n",
    "\n",
    "\n",
    "# Пример вызова валидации\n",
    "test_accuracy = validate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()\n",
    "task.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
