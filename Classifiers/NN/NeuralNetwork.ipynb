{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "script_path = os.path.join(os.getcwd(), \"../../Scripts/\")\n",
    "sys.path.append(script_path)\n",
    "import data_generator as dgen\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import yaml\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score\n",
    "\n",
    "import mlflow\n",
    "from clearml import Task, Logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создаем таску в clearML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=5240398dee3242bc800fce4a3b3c128c\n",
      "ClearML results page: https://app.clear.ml/projects/fb3fda3d43384b2d8e49fef268418091/experiments/5240398dee3242bc800fce4a3b3c128c/output/log\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "run_name = f\"Run-{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "task = Task.init(\n",
    "    project_name=\"Diploma Multibranch net\",\n",
    "    task_name=run_name,\n",
    "    task_type=Task.TaskTypes.training,\n",
    ")\n",
    "\n",
    "task.set_system_tags([\"gpu_monitoring\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGDataAugmentation:\n",
    "    def __init__(self, noise_level=0.01, shift_range=0.1, mask_prob=0.1):\n",
    "        \"\"\"\n",
    "        Аргументы:\n",
    "        noise_level (float): Уровень шума, добавляемого к сигналу.\n",
    "        shift_range (float): Максимальный сдвиг сигнала, выраженный в доле от длины.\n",
    "        mask_prob (float): Вероятность маскирования случайных интервалов.\n",
    "        \"\"\"\n",
    "        self.noise_level = noise_level\n",
    "        self.shift_range = shift_range\n",
    "        self.mask_prob = mask_prob\n",
    "\n",
    "    def add_noise(self, signal):\n",
    "        \"\"\"Добавляем гауссовский шум к сигналу.\"\"\"\n",
    "        noise = torch.randn_like(signal) * self.noise_level\n",
    "        return signal + noise\n",
    "\n",
    "    def shift_signal(self, signal):\n",
    "        \"\"\"Сдвигаем сигнал на случайное значение в пределах shift_range.\"\"\"\n",
    "        shift_amount = int(self.shift_range * signal.size(-1))\n",
    "        shift = np.random.randint(-shift_amount, shift_amount)\n",
    "        return torch.roll(signal, shifts=shift, dims=-1)\n",
    "\n",
    "    def mask_random_intervals(self, signal):\n",
    "        \"\"\"Маскируем случайные интервалы в сигнале, заменяя их на нули.\"\"\"\n",
    "        mask = torch.rand(signal.size()) < self.mask_prob\n",
    "        signal = signal.masked_fill(mask, 0)\n",
    "        return signal\n",
    "\n",
    "    def __call__(self, signal):\n",
    "        \"\"\"Применяем все аугментации.\"\"\"\n",
    "        signal = self.add_noise(signal)\n",
    "        signal = self.shift_signal(signal)\n",
    "        signal = self.mask_random_intervals(signal)\n",
    "        return signal\n",
    "\n",
    "\n",
    "data_augmentation = ECGDataAugmentation(\n",
    "    noise_level=0.01, shift_range=0.1, mask_prob=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190, 8, 5000)\n",
      "(2, 190)\n",
      "(380, 8, 5000)\n",
      "(2, 380)\n"
     ]
    }
   ],
   "source": [
    "# Примерная функция для нормализации\n",
    "def normalize(signal):\n",
    "    return (signal - np.mean(signal)) / np.std(signal)\n",
    "\n",
    "\n",
    "# Класс для подготовки датасета\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.fixed_length = 5000  # Пример длины для padding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Берем данные пациента\n",
    "        ecg_signal = self.data[idx]\n",
    "\n",
    "        # Применяем нормализацию к каждому каналу\n",
    "        ecg_signal = np.array([normalize(ch) for ch in ecg_signal])\n",
    "\n",
    "        # Padding/Truncation до фиксированной длины\n",
    "        ecg_signal = self._fix_length(ecg_signal)\n",
    "\n",
    "        # Преобразование в torch.tensor\n",
    "        ecg_signal = torch.tensor(ecg_signal, dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return ecg_signal, label\n",
    "\n",
    "    def _fix_length(self, ecg_signal):\n",
    "        # Применяем padding или обрезание\n",
    "        if ecg_signal.shape[1] < self.fixed_length:\n",
    "            pad_size = self.fixed_length - ecg_signal.shape[1]\n",
    "            ecg_signal = np.pad(ecg_signal, ((0, 0), (0, pad_size)), \"constant\")\n",
    "        else:\n",
    "            ecg_signal = ecg_signal[:, : self.fixed_length]\n",
    "        return ecg_signal\n",
    "\n",
    "\n",
    "def create_weighted_sampler(labels):\n",
    "    class_counts = torch.bincount(labels)\n",
    "    class_weights = 1.0 / class_counts.float()\n",
    "    sample_weights = class_weights[labels]\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=sample_weights, num_samples=len(labels), replacement=True\n",
    "    )\n",
    "    return sampler\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"../../Data/dumped/X_train.pkl\", \"rb\") as f:\n",
    "    f.seek(0)\n",
    "    X_train = pickle.load(f)\n",
    "with open(\"../../Data/dumped/y_train.pkl\", \"rb\") as f:\n",
    "    f.seek(0)\n",
    "    y_train = pickle.load(f)\n",
    "with open(\"../../Data/dumped/X_test.pkl\", \"rb\") as f:\n",
    "    f.seek(0)\n",
    "    X_test = pickle.load(f)\n",
    "with open(\"../../Data/dumped/y_test.pkl\", \"rb\") as f:\n",
    "    f.seek(0)\n",
    "    y_test = pickle.load(f)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "y_train = np.concatenate([y_train, y_train], axis=1)\n",
    "Y_train = y_train[0].astype(\"int8\")\n",
    "Y_test = y_test[0].astype(\"int8\")\n",
    "# Y_train = F.one_hot(torch.LongTensor(y_train[0]), num_classes=2).double()\n",
    "# Y_train.double()\n",
    "# Y_test = F.one_hot(torch.LongTensor(y_test[0]), num_classes=2).double()\n",
    "# Y_test.double()\n",
    "# Y_train = y_train[0]\n",
    "# Y_test = y_test[0]\n",
    "\n",
    "\n",
    "X_train = np.concatenate(\n",
    "    [X_train, np.array([data_augmentation(torch.tensor(x)).numpy() for x in X_train])],\n",
    "    axis=0,\n",
    ")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "sampler = create_weighted_sampler(torch.LongTensor(Y_train))\n",
    "train_dataset = ECGDataset(data=X_train, labels=Y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "\n",
    "test_dataset = ECGDataset(data=X_test, labels=Y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерируем yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "unique_train, counts_train = np.unique(Y_train, return_counts=True)\n",
    "unique_test, counts_test = np.unique(Y_test, return_counts=True)\n",
    "train_dict = dict(zip(unique_train, counts_train))\n",
    "test_dict = dict(zip(unique_test, counts_test))\n",
    "\n",
    "# Определяем конфигурацию\n",
    "config = {\n",
    "    \"model\": {\n",
    "        \"architecture\": \"MultiBranchECGNet\",\n",
    "        \"num_channels\": 8,\n",
    "        \"num_classes\": 2,\n",
    "        \"parameters\": {\"learning_rate\": 0.001, \"dropout_rate\": 0.5},\n",
    "    },\n",
    "    \"optimizer\": {\"type\": \"Adam\", \"parameters\": {\"lr\": 0.001, \"weight_decay\": 1e-4}},\n",
    "    \"loss_function\": {\n",
    "        \"type\": \"BCEWithLogitsLoss\",\n",
    "        \"parameters\": {\"alpha\": 2.0, \"gamma\": 3.0, \"pos_weight\": [6, 1]},\n",
    "    },\n",
    "    \"dataset\": {\n",
    "        \"train_size\": len(train_dataset),\n",
    "        \"test_size\": len(test_dataset),\n",
    "        \"class_distribution\": {\n",
    "            \"train\": {0 : int(train_dict[0]), 1: int(train_dict[1])},\n",
    "            \"test\": {0 : int(test_dict[0]), 1: int(test_dict[1])},\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# Сохраняем в файл\n",
    "with open(\"config.yaml\", \"w\") as f:\n",
    "    yaml.dump(config, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ECGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGNet, self).__init__()\n",
    "\n",
    "        # Сверточные слои\n",
    "        self.conv1 = nn.Conv1d(in_channels=8, out_channels=16, kernel_size=7, padding=3)\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=16, out_channels=32, kernel_size=5, padding=2\n",
    "        )\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        # LSTM слой для захвата временных зависимостей\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=32,\n",
    "            hidden_size=64,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "\n",
    "        # Полносвязные слои\n",
    "        self.fc1 = nn.Linear(64 * 2, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)  # Предполагается 3 класса болезней\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, 8, seq_len]\n",
    "\n",
    "        # Свертка\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        # Подготовка для LSTM\n",
    "        # Меняем размер на [batch_size, seq_len, channels] для LSTM\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # LSTM\n",
    "        x, (hn, cn) = self.lstm(x)\n",
    "\n",
    "        # Берем последнее скрытое состояние LSTM\n",
    "        x = x[:, -1, :]  # [batch_size, 64*2]\n",
    "\n",
    "        # Полносвязные слои\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # [batch_size, num_classes]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiBranchECGNet(nn.Module):\n",
    "    def __init__(self, num_channels=8, num_classes=3):\n",
    "        super(MultiBranchECGNet, self).__init__()\n",
    "\n",
    "        # Ветви для каждого канала (CNN)\n",
    "        self.branches = nn.ModuleList(\n",
    "            [self.create_branch() for _ in range(num_channels)]\n",
    "        )\n",
    "\n",
    "        # Attention слой для агрегации информации между каналами\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=128, num_heads=8, batch_first=True\n",
    "        )\n",
    "\n",
    "        # Линейный слой для выравнивания размерности перед attention\n",
    "        self.linear_attn = nn.Linear(num_channels * 128, 128)\n",
    "\n",
    "        # Полносвязные слои для классификации\n",
    "        self.fc1 = nn.Linear(128, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        self.drop = nn.Dropout(p=config[\"model\"][\"parameters\"][\"dropout_rate\"])\n",
    "\n",
    "    def create_branch(self):\n",
    "        \"\"\"Создаем сверточную ветвь для каждого канала\"\"\"\n",
    "        branch = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=7, padding=3),  # Свертка с padding\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(32, 64, kernel_size=5, padding=2),  # Вторая сверточная операция\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),  # Третья сверточная операция\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "        )\n",
    "        return branch\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, num_channels, seq_len]\n",
    "\n",
    "        # Обрабатываем каждый канал через свою ветвь (CNN для каждого канала)\n",
    "        branch_outputs = []\n",
    "        for i in range(x.size(1)):  # num_channels\n",
    "            branch_output = self.branches[i](\n",
    "                x[:, i : i + 1, :]\n",
    "            )  # Обрабатываем i-й канал, [batch_size, 1, seq_len]\n",
    "            branch_outputs.append(branch_output)\n",
    "\n",
    "        # Объединяем выходы ветвей\n",
    "        out = torch.stack(\n",
    "            branch_outputs, dim=1\n",
    "        )  # [batch_size, num_channels, 128, reduced_seq_len]\n",
    "\n",
    "        # out = out.mean(dim=-1)  # Усредняем по временной оси: [batch_size, num_channels, 128]\n",
    "\n",
    "        # # Применяем multi-head attention для межканальной агрегации\n",
    "        # out, _ = self.attention(out, out, out)  # [batch_size, num_channels, 128]\n",
    "\n",
    "        # # Flatten the output\n",
    "        # out = torch.flatten(out, start_dim=1, end_dim=2)  # [batch_size, num_channels * 128]\n",
    "\n",
    "        # Меняем форму, чтобы соответствовать входу MultiheadAttention: [batch_size, reduced_seq_len, num_channels * 128]\n",
    "        batch_size, num_channels, embed_dim, seq_len = out.shape\n",
    "        out = out.permute(0, 3, 1, 2).reshape(batch_size, seq_len, -1)\n",
    "\n",
    "        out = F.relu(self.linear_attn(out))\n",
    "\n",
    "        # Применяем Multihead Attention ко всей последовательности\n",
    "        out, _ = self.attention(\n",
    "            out, out, out\n",
    "        )  # [batch_size, seq_len, num_channels * 128]\n",
    "\n",
    "        # Усредняем по временной оси\n",
    "        out = out.mean(dim=1)  # [batch_size, num_channels * 128]\n",
    "\n",
    "        # Полносвязные слои для классификации\n",
    "        out = F.relu(self.drop(self.fc1(out)))\n",
    "        out = self.fc2(out)  # [batch_size, num_classes]\n",
    "        return out\n",
    "\n",
    "\n",
    "# Пример использования\n",
    "model = MultiBranchECGNet(num_channels=8, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction=\"mean\"):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "        if self.reduction == \"mean\":\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80, Loss: 1.1847\n",
      "Epoch 2/80, Loss: 1.0111\n",
      "Epoch 3/80, Loss: 0.9157\n",
      "Epoch 4/80, Loss: 0.8813\n",
      "Epoch 5/80, Loss: 0.7275\n",
      "Epoch 6/80, Loss: 0.7140\n",
      "Epoch 7/80, Loss: 0.5302\n",
      "Epoch 8/80, Loss: 0.6439\n",
      "Epoch 9/80, Loss: 0.5643\n",
      "Epoch 10/80, Loss: 0.3921\n",
      "Epoch 11/80, Loss: 0.6098\n",
      "Epoch 12/80, Loss: 0.5760\n",
      "Epoch 13/80, Loss: 0.4571\n",
      "Epoch 14/80, Loss: 0.3746\n",
      "Epoch 15/80, Loss: 0.4909\n",
      "Epoch 16/80, Loss: 0.4136\n",
      "Epoch 17/80, Loss: 0.4727\n",
      "Epoch 18/80, Loss: 0.3359\n",
      "Epoch 19/80, Loss: 0.4598\n"
     ]
    }
   ],
   "source": [
    "loss_type = config[\"loss_function\"][\"type\"]\n",
    "\n",
    "if loss_type == \"FocalLoss\":\n",
    "    criterion = FocalLoss(\n",
    "        alpha=config[\"loss_function\"][\"parameters\"][\"alpha\"],\n",
    "        gamma=config[\"loss_function\"][\"parameters\"][\"gamma\"],\n",
    "    )\n",
    "elif loss_type == \"BCEWithLogitsLoss\":\n",
    "    pos_weight = torch.tensor(config[\"loss_function\"][\"parameters\"][\"pos_weight\"])\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown loss function type: {loss_type}\")\n",
    "\n",
    "# criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "# criterion = FocalLoss(alpha=2, gamma=3)\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=config[\"optimizer\"][\"parameters\"][\"lr\"],\n",
    "    weight_decay=config[\"optimizer\"][\"parameters\"][\"weight_decay\"],\n",
    ")\n",
    "\n",
    "\n",
    "# Обучение модели\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=10, patience=10):\n",
    "    best_valid_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        for inputs, labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            # labels.type(torch.FloatTensor)\n",
    "\n",
    "            # labels = labels.type(torch.FloatTensor) \\\n",
    "            #   .reshape((labels.shape[0], 2))\n",
    "\n",
    "            labels = F.one_hot(labels, num_classes=2).float()\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            all_preds.extend(torch.argmax(outputs, dim=1))\n",
    "            all_labels.extend(torch.argmax(labels, dim=1))\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        recall = recall_score(all_labels, all_preds)\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        precision = precision_score(all_labels, all_preds)\n",
    "\n",
    "        Logger.current_logger().report_scalar(\"Accuracy\", \"Train\", accuracy, epoch)\n",
    "        Logger.current_logger().report_scalar(\"Loss\", \"Train\", epoch_loss, epoch)\n",
    "        Logger.current_logger().report_scalar(\"Recall\", \"Train\", recall, epoch)\n",
    "        Logger.current_logger().report_scalar(\"Precision\", \"Train\", precision, epoch)\n",
    "\n",
    "        mlflow.log_metric(\"Train Accuracy\", accuracy, step=epoch)\n",
    "        mlflow.log_metric(\"Train Loss\", epoch_loss, step=epoch)\n",
    "        mlflow.log_metric(\"Train Recall\", recall, step=epoch)\n",
    "        mlflow.log_metric(\"Train Precision\", precision, step=epoch)\n",
    "\n",
    "        # if epoch_loss < best_valid_loss:\n",
    "        #     best_valid_loss = epoch_loss\n",
    "        #     print(f\"\\nBest validation loss: {best_valid_loss}\")\n",
    "        #     print(f\"\\nSaving best model for epoch: {epoch+1}\\n\")\n",
    "        #     torch.save(model, 'best_model.pt')\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "\n",
    "# Запуск обучения\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сохранение модели\n",
    "torch.save(model.state_dict(), \"model_weights.pth\")\n",
    "task.upload_artifact(name=\"Model Weights\", artifact_object=\"model_weights.pth\")\n",
    "\n",
    "# Сохранение конфигурации\n",
    "task.upload_artifact(name=\"Config File\", artifact_object=\"config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connecting multiple input models with the same name: `model_weights`. This might result in the wrong model being used when executing remotely\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation recall: 0.3750\n",
      "Validation accuracy: 0.7292\n",
      "Validation precision: 0.2727\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83        40\n",
      "           1       0.27      0.38      0.32         8\n",
      "\n",
      "    accuracy                           0.73        48\n",
      "   macro avg       0.57      0.59      0.57        48\n",
      "weighted avg       0.77      0.73      0.75        48\n",
      "\n",
      "Матрица несоответствий для тестовой выборки метода ЛДА:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def validate_model(model, dataloader):\n",
    "    model = MultiBranchECGNet(num_channels=8, num_classes=2)\n",
    "    model.load_state_dict(torch.load(\"model_weights.pth\", weights_only=True))\n",
    "    model.eval()  # Переводим модель в режим оценки\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():  # Отключаем градиенты для валидации\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)  # Предсказания с максимальной вероятностью\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    # Преобразуем в numpy массивы\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    # all_labels = np.argmax(all_labels, axis=1)\n",
    "\n",
    "    # Считаем accuracy\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    print(f\"Validation recall: {recall:.4f}\")\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Validation accuracy: {accuracy:.4f}\")\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    print(f\"Validation precision: {precision:.4f}\")\n",
    "\n",
    "    class_names = [\"Норм. ритм\", \"Амилоидоз\"]\n",
    "\n",
    "    print(\"\\n clasification report:\\n\", classification_report(all_labels, all_preds))\n",
    "\n",
    "    print(\"Матрица несоответствий для тестовой выборки метода ЛДА:\\n\")\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    disp = ConfusionMatrixDisplay(\n",
    "        confusion_matrix(all_labels, all_preds), display_labels=class_names\n",
    "    )\n",
    "    disp.plot(cmap=\"Blues\", ax=ax)\n",
    "\n",
    "    Logger.current_logger().report_confusion_matrix(\n",
    "        title=\"Confusion Matrix\",\n",
    "        series=\"Validation Results\",\n",
    "        matrix=confusion_matrix(all_labels, all_preds),\n",
    "        yaxis_reversed=True,\n",
    "        xaxis=\"Predicted\",\n",
    "        yaxis=\"Expected\",\n",
    "        xlabels=class_names,\n",
    "        ylabels=class_names\n",
    "    )\n",
    "\n",
    "    return recall\n",
    "\n",
    "\n",
    "# Пример вызова валидации\n",
    "test_accuracy = validate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()\n",
    "task.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
