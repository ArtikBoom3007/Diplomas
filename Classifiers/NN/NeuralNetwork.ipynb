{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "script_path = os.path.join(os.getcwd(), \"../../Scripts/\")\n",
    "sys.path.append(script_path)\n",
    "import data_generator as dgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Примерная функция для нормализации\n",
    "def normalize(signal):\n",
    "    return (signal - np.mean(signal)) / np.std(signal)\n",
    "\n",
    "# Класс для подготовки датасета\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.fixed_length = 5000  # Пример длины для padding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Берем данные пациента\n",
    "        ecg_signal = self.data[idx]\n",
    "        \n",
    "        # Применяем нормализацию к каждому каналу\n",
    "        ecg_signal = np.array([normalize(ch) for ch in ecg_signal])\n",
    "        \n",
    "        # Padding/Truncation до фиксированной длины\n",
    "        ecg_signal = self._fix_length(ecg_signal)\n",
    "        \n",
    "        # Преобразование в torch.tensor\n",
    "        ecg_signal = torch.tensor(ecg_signal, dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        \n",
    "        return ecg_signal, label\n",
    "    \n",
    "    def _fix_length(self, ecg_signal):\n",
    "        # Применяем padding или обрезание\n",
    "        if ecg_signal.shape[1] < self.fixed_length:\n",
    "            pad_size = self.fixed_length - ecg_signal.shape[1]\n",
    "            ecg_signal = np.pad(ecg_signal, ((0, 0), (0, pad_size)), 'constant')\n",
    "        else:\n",
    "            ecg_signal = ecg_signal[:, :self.fixed_length]\n",
    "        return ecg_signal\n",
    "\n",
    "# Пример использования\n",
    "# data = список из N записей, каждая содержит 8 каналов\n",
    "# labels = список меток заболеваний\n",
    "# dgen.init(filter=True)\n",
    "# amy, amyc, norm, amy_h, amyc_h, norm_h = dgen.read_data_with_meta()\n",
    "\n",
    "# X = norm + amyc + amy\n",
    "# y = np.concatenate([np.zeros(len(norm) + len(amyc)), np.ones(len(amy))])\n",
    "\n",
    "import pickle\n",
    "with open('../../Data/dumped/X_train.pkl', 'rb') as f:\n",
    "    f.seek(0)\n",
    "    X_train = pickle.load(f)\n",
    "with open('../../Data/dumped/y_train.pkl', 'rb') as f:\n",
    "    f.seek(0)\n",
    "    y_train = pickle.load(f)\n",
    "with open('../../Data/dumped/X_test.pkl', 'rb') as f:\n",
    "    f.seek(0)\n",
    "    X_test = pickle.load(f)\n",
    "with open('../../Data/dumped/y_test.pkl', 'rb') as f:\n",
    "    f.seek(0)\n",
    "    y_test = pickle.load(f)\n",
    "\n",
    "train_dataset = ECGDataset(data=X_train, labels=y_train[0])\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = ECGDataset(data=X_test, labels=y_test[0])\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ECGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGNet, self).__init__()\n",
    "        \n",
    "        # Сверточные слои\n",
    "        self.conv1 = nn.Conv1d(in_channels=8, out_channels=16, kernel_size=7, padding=3)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=5, padding=2)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        # LSTM слой для захвата временных зависимостей\n",
    "        self.lstm = nn.LSTM(input_size=32, hidden_size=64, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # Полносвязные слои\n",
    "        self.fc1 = nn.Linear(64*2, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)  # Предполагается 3 класса болезней\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, 8, seq_len]\n",
    "        \n",
    "        # Свертка\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # Подготовка для LSTM\n",
    "        # Меняем размер на [batch_size, seq_len, channels] для LSTM\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        # LSTM\n",
    "        x, (hn, cn) = self.lstm(x)\n",
    "        \n",
    "        # Берем последнее скрытое состояние LSTM\n",
    "        x = x[:, -1, :]  # [batch_size, 64*2]\n",
    "        \n",
    "        # Полносвязные слои\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # [batch_size, num_classes]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример обучения\n",
    "model = ECGNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=25):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in dataloader:\n",
    "            # Обнуление градиентов\n",
    "            optimizer.zero_grad()\n",
    "            inputs.to(device=\"cuda\")\n",
    "            labels.to(device='cuda')\n",
    "            # Прямой проход\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Обратный проход и оптимизация\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "# Запуск обучения\n",
    "# train_model(model, train_loader, criterion, optimizer, num_epochs=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiBranchECGNet(nn.Module):\n",
    "#     def __init__(self, num_channels=8, num_classes=3):\n",
    "#         super(MultiBranchECGNet, self).__init__()\n",
    "        \n",
    "#         # Создаем отдельную ветвь для каждого канала\n",
    "#         self.branches = nn.ModuleList([self.create_branch() for _ in range(num_channels)])\n",
    "        \n",
    "#         # Полносвязные слои после объединения всех ветвей\n",
    "#         self.fc1 = nn.Linear(1248, 128)\n",
    "#         self.fc2 = nn.Linear(128, num_classes)\n",
    "#         self.max_pool = nn.MaxPool2d(4)\n",
    "#         self.conv_1 = nn.Conv1d(256, 64, kernel_size=5, padding=2)\n",
    "#         self.conv_2 = nn.Conv1d(64, 32, kernel_size=5, padding=2)\n",
    "#         self.conv_3 = nn.Conv1d(32, 16, kernel_size=5, padding=2)\n",
    "#         self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    \n",
    "#     def create_branch(self):\n",
    "#         # Каждый канал проходит через свою сверточную ветвь\n",
    "#         branch = nn.Sequential(\n",
    "#             nn.Conv1d(1, 16, kernel_size=7, padding=3),  # Свертка с padding\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool1d(2),\n",
    "#             nn.Conv1d(16, 32, kernel_size=5, padding=2),  # Вторая с вертка\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool1d(2)\n",
    "#         )\n",
    "#         return branch\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         # x shape: [batch_size, num_channels, seq_len]\n",
    "        \n",
    "#         # Пропускаем каждый канал через свою ветвь\n",
    "#         branch_outputs = []\n",
    "#         for i in range(x.size(1)):  # num_channels\n",
    "#             branch_output = self.branches[i](x[:, i:i+1, :])  # Обрабатываем i-й канал\n",
    "#             branch_outputs.append(branch_output)\n",
    "        \n",
    "#         # Объединяем выходы всех ветвей\n",
    "#         out = torch.cat(branch_outputs, dim=1)  # Соединяем по оси каналов\n",
    "\n",
    "#         out = F.relu(self.conv_1(out))\n",
    "\n",
    "#         out = F.relu(self.conv_2(out))\n",
    "\n",
    "#         out = F.relu(self.conv_3(out))\n",
    "\n",
    "#         out = self.max_pool(out)\n",
    "        \n",
    "#         # Преобразуем для подачи на полносвязные слои\n",
    "#         out = out.view(out.size(0), -1)  # Flatten\n",
    "        \n",
    "#         # Полносвязные слои\n",
    "#         out = F.relu(self.dropout(self.fc1(out)))\n",
    "#         out = self.fc2(out)\n",
    "        \n",
    "#         return out\n",
    "\n",
    "# # Пример использования\n",
    "# model = MultiBranchECGNet(num_channels=8, num_classes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiBranchECGNet(nn.Module):\n",
    "    def __init__(self, num_channels=8, num_classes=3):\n",
    "        super(MultiBranchECGNet, self).__init__()\n",
    "        \n",
    "        # Ветви для каждого канала (CNN)\n",
    "        self.branches = nn.ModuleList([self.create_branch() for _ in range(num_channels)])\n",
    "        \n",
    "        # Attention слой для агрегации информации между каналами\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=128, num_heads=8, batch_first=True)\n",
    "        \n",
    "        # Полносвязные слои для классификации\n",
    "        self.fc1 = nn.Linear(128 * num_channels, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "    \n",
    "    def create_branch(self):\n",
    "        \"\"\"Создаем сверточную ветвь для каждого канала\"\"\"\n",
    "        branch = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=7, padding=3),  # Свертка с padding\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(32, 64, kernel_size=5, padding=2),  # Вторая сверточная операция\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),  # Третья сверточная операция\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "        return branch\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, num_channels, seq_len]\n",
    "        \n",
    "        # Обрабатываем каждый канал через свою ветвь (CNN для каждого канала)\n",
    "        branch_outputs = []\n",
    "        for i in range(x.size(1)):  # num_channels\n",
    "            branch_output = self.branches[i](x[:, i:i+1, :])  # Обрабатываем i-й канал, [batch_size, 1, seq_len]\n",
    "            branch_outputs.append(branch_output)\n",
    "        \n",
    "        # Объединяем выходы ветвей\n",
    "        out = torch.stack(branch_outputs, dim=1)  # [batch_size, num_channels, 128, reduced_seq_len]\n",
    "        out = out.mean(dim=-1)  # Усредняем по временной оси: [batch_size, num_channels, 128]\n",
    "        \n",
    "        # Применяем multi-head attention для межканальной агрегации\n",
    "        out, _ = self.attention(out, out, out)  # [batch_size, num_channels, 128]\n",
    "        \n",
    "        # Flatten the output\n",
    "        out = torch.flatten(out, start_dim=1, end_dim=2)  # [batch_size, num_channels * 128]\n",
    "        \n",
    "        # Полносвязные слои для классификации\n",
    "        out = F.relu(self.drop(self.fc1(out)))\n",
    "        out = self.fc2(out)  # [batch_size, num_classes]\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Пример использования\n",
    "model = MultiBranchECGNet(num_channels=8, num_classes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60, Loss: 0.7361\n",
      "Epoch 2/60, Loss: 0.6977\n",
      "Epoch 3/60, Loss: 0.6886\n",
      "Epoch 4/60, Loss: 0.6914\n",
      "Epoch 5/60, Loss: 0.6808\n",
      "Epoch 6/60, Loss: 0.6751\n",
      "Epoch 7/60, Loss: 0.6756\n",
      "Epoch 8/60, Loss: 0.6617\n",
      "Epoch 9/60, Loss: 0.6475\n",
      "Epoch 10/60, Loss: 0.6366\n",
      "Epoch 11/60, Loss: 0.6181\n",
      "Epoch 12/60, Loss: 0.6617\n",
      "Epoch 13/60, Loss: 0.5577\n",
      "Epoch 14/60, Loss: 0.6177\n",
      "Epoch 15/60, Loss: 0.5607\n",
      "Epoch 16/60, Loss: 0.5195\n",
      "Epoch 17/60, Loss: 0.4837\n",
      "Epoch 18/60, Loss: 0.4684\n",
      "Epoch 19/60, Loss: 0.6386\n",
      "Epoch 20/60, Loss: 0.4320\n",
      "Epoch 21/60, Loss: 0.4513\n",
      "Epoch 22/60, Loss: 0.4678\n",
      "Epoch 23/60, Loss: 0.4529\n",
      "Epoch 24/60, Loss: 0.4922\n",
      "Epoch 25/60, Loss: 0.5102\n",
      "Epoch 26/60, Loss: 0.4506\n",
      "Epoch 27/60, Loss: 0.5679\n",
      "Epoch 28/60, Loss: 0.4346\n",
      "Epoch 29/60, Loss: 0.4029\n",
      "Epoch 30/60, Loss: 0.3939\n",
      "Epoch 31/60, Loss: 0.3715\n",
      "Epoch 32/60, Loss: 0.3208\n",
      "Epoch 33/60, Loss: 0.4051\n",
      "Epoch 34/60, Loss: 0.2869\n",
      "Epoch 35/60, Loss: 0.2621\n",
      "Epoch 36/60, Loss: 0.3989\n",
      "Epoch 37/60, Loss: 0.4522\n",
      "Epoch 38/60, Loss: 0.2722\n",
      "Epoch 39/60, Loss: 0.3120\n",
      "Epoch 40/60, Loss: 0.3554\n",
      "Epoch 41/60, Loss: 0.2593\n",
      "Epoch 42/60, Loss: 0.3564\n",
      "Epoch 43/60, Loss: 0.3120\n",
      "Epoch 44/60, Loss: 0.5020\n",
      "Epoch 45/60, Loss: 0.3243\n",
      "Epoch 46/60, Loss: 0.3624\n",
      "Epoch 47/60, Loss: 0.3052\n",
      "Epoch 48/60, Loss: 0.2370\n",
      "Epoch 49/60, Loss: 0.1708\n",
      "Epoch 50/60, Loss: 0.1907\n",
      "Epoch 51/60, Loss: 0.6536\n",
      "Epoch 52/60, Loss: 0.3098\n",
      "Epoch 53/60, Loss: 0.2954\n",
      "Epoch 54/60, Loss: 0.2271\n",
      "Epoch 55/60, Loss: 0.2646\n",
      "Epoch 56/60, Loss: 0.3157\n",
      "Epoch 57/60, Loss: 0.3631\n",
      "Epoch 58/60, Loss: 0.2359\n",
      "Epoch 59/60, Loss: 0.2257\n",
      "Epoch 60/60, Loss: 0.1280\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Обучение модели\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "# Запуск обучения\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 0 0 1 0 1]\n",
      "[1 0 1 0 0 1 0 1 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0 0]\n",
      "Validation recall: 0.8333\n",
      "Validation accuracy: 0.7200\n",
      "Validation precision: 0.6667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, accuracy_score, precision_score\n",
    "\n",
    "def validate_model(model, dataloader):\n",
    "    model.eval()  # Переводим модель в режим оценки\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():  # Отключаем градиенты для валидации\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)  # Предсказания с максимальной вероятностью\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    # Преобразуем в numpy массивы\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    print(all_preds)\n",
    "    print(all_labels)\n",
    "    \n",
    "    # Считаем accuracy\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    print(f'Validation recall: {recall:.4f}')\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f'Validation accuracy: {accuracy:.4f}')\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    print(f'Validation precision: {precision:.4f}')\n",
    "    \n",
    "    return recall\n",
    "\n",
    "# Пример вызова валидации\n",
    "test_accuracy = validate_model(model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
