{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "script_path = os.path.join(os.getcwd(), \"../../Scripts/\")\n",
    "sys.path.append(script_path)\n",
    "import data_generator as dgen\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import yaml\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score\n",
    "\n",
    "import mlflow\n",
    "from clearml import Task, Logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создаем таску в clearML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=f369df59117a41ee990502bae10aad10\n",
      "2024-11-24 14:53:34,760 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "ClearML results page: https://app.clear.ml/projects/fb3fda3d43384b2d8e49fef268418091/experiments/f369df59117a41ee990502bae10aad10/output/log\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "run_name = f\"Run-{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "task = Task.init(\n",
    "    project_name=\"Diploma Multibranch net\",\n",
    "    task_name=run_name,\n",
    "    task_type=Task.TaskTypes.training,\n",
    ")\n",
    "\n",
    "task.set_system_tags([\"gpu_monitoring\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGDataAugmentation:\n",
    "    def __init__(self, noise_level=0.01, shift_range=0.1, mask_prob=0.1):\n",
    "        \"\"\"\n",
    "        Аргументы:\n",
    "        noise_level (float): Уровень шума, добавляемого к сигналу.\n",
    "        shift_range (float): Максимальный сдвиг сигнала, выраженный в доле от длины.\n",
    "        mask_prob (float): Вероятность маскирования случайных интервалов.\n",
    "        \"\"\"\n",
    "        self.noise_level = noise_level\n",
    "        self.shift_range = shift_range\n",
    "        self.mask_prob = mask_prob\n",
    "\n",
    "    def add_noise(self, signal):\n",
    "        \"\"\"Добавляем гауссовский шум к сигналу.\"\"\"\n",
    "        noise = torch.randn_like(signal) * self.noise_level\n",
    "        return signal + noise\n",
    "\n",
    "    def shift_signal(self, signal):\n",
    "        \"\"\"Сдвигаем сигнал на случайное значение в пределах shift_range.\"\"\"\n",
    "        shift_amount = int(self.shift_range * signal.size(-1))\n",
    "        shift = np.random.randint(-shift_amount, shift_amount)\n",
    "        return torch.roll(signal, shifts=shift, dims=-1)\n",
    "\n",
    "    def mask_random_intervals(self, signal):\n",
    "        \"\"\"Маскируем случайные интервалы в сигнале, заменяя их на нули.\"\"\"\n",
    "        mask = torch.rand(signal.size()) < self.mask_prob\n",
    "        signal = signal.masked_fill(mask, 0)\n",
    "        return signal\n",
    "\n",
    "    def __call__(self, signal):\n",
    "        \"\"\"Применяем все аугментации.\"\"\"\n",
    "        signal = self.add_noise(signal)\n",
    "        signal = self.shift_signal(signal)\n",
    "        signal = self.mask_random_intervals(signal)\n",
    "        return signal\n",
    "\n",
    "\n",
    "data_augmentation = ECGDataAugmentation(\n",
    "    noise_level=0.01, shift_range=0.1, mask_prob=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190, 8, 5000)\n",
      "(2, 190)\n",
      "(380, 8, 5000)\n",
      "(2, 380)\n"
     ]
    }
   ],
   "source": [
    "# Примерная функция для нормализации\n",
    "def normalize(signal):\n",
    "    return (signal - np.mean(signal)) / np.std(signal)\n",
    "\n",
    "\n",
    "# Класс для подготовки датасета\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.fixed_length = 5000  # Пример длины для padding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Берем данные пациента\n",
    "        ecg_signal = self.data[idx]\n",
    "\n",
    "        # Применяем нормализацию к каждому каналу\n",
    "        ecg_signal = np.array([normalize(ch) for ch in ecg_signal])\n",
    "\n",
    "        # Padding/Truncation до фиксированной длины\n",
    "        ecg_signal = self._fix_length(ecg_signal)\n",
    "\n",
    "        # Преобразование в torch.tensor\n",
    "        ecg_signal = torch.tensor(ecg_signal, dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return ecg_signal, label\n",
    "\n",
    "    def _fix_length(self, ecg_signal):\n",
    "        # Применяем padding или обрезание\n",
    "        if ecg_signal.shape[1] < self.fixed_length:\n",
    "            pad_size = self.fixed_length - ecg_signal.shape[1]\n",
    "            ecg_signal = np.pad(ecg_signal, ((0, 0), (0, pad_size)), \"constant\")\n",
    "        else:\n",
    "            ecg_signal = ecg_signal[:, : self.fixed_length]\n",
    "        return ecg_signal\n",
    "\n",
    "\n",
    "def create_weighted_sampler(labels):\n",
    "    class_counts = torch.bincount(labels)\n",
    "    class_weights = 1.0 / class_counts.float()\n",
    "    sample_weights = class_weights[labels]\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=sample_weights, num_samples=len(labels), replacement=True\n",
    "    )\n",
    "    return sampler\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"../../Data/dumped/X_train.pkl\", \"rb\") as f:\n",
    "    f.seek(0)\n",
    "    X_train = pickle.load(f)\n",
    "with open(\"../../Data/dumped/y_train.pkl\", \"rb\") as f:\n",
    "    f.seek(0)\n",
    "    y_train = pickle.load(f)\n",
    "with open(\"../../Data/dumped/X_test.pkl\", \"rb\") as f:\n",
    "    f.seek(0)\n",
    "    X_test = pickle.load(f)\n",
    "with open(\"../../Data/dumped/y_test.pkl\", \"rb\") as f:\n",
    "    f.seek(0)\n",
    "    y_test = pickle.load(f)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "y_train = np.concatenate([y_train, y_train], axis=1)\n",
    "Y_train = y_train[0].astype(\"int8\")\n",
    "Y_test = y_test[0].astype(\"int8\")\n",
    "# Y_train = F.one_hot(torch.LongTensor(y_train[0]), num_classes=2).double()\n",
    "# Y_train.double()\n",
    "# Y_test = F.one_hot(torch.LongTensor(y_test[0]), num_classes=2).double()\n",
    "# Y_test.double()\n",
    "# Y_train = y_train[0]\n",
    "# Y_test = y_test[0]\n",
    "\n",
    "\n",
    "X_train = np.concatenate(\n",
    "    [X_train, np.array([data_augmentation(torch.tensor(x)).numpy() for x in X_train])],\n",
    "    axis=0,\n",
    ")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "sampler = create_weighted_sampler(torch.LongTensor(Y_train))\n",
    "train_dataset = ECGDataset(data=X_train, labels=Y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "\n",
    "test_dataset = ECGDataset(data=X_test, labels=Y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерируем yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "unique_train, counts_train = np.unique(Y_train, return_counts=True)\n",
    "unique_test, counts_test = np.unique(Y_test, return_counts=True)\n",
    "train_dict = dict(zip(unique_train, counts_train))\n",
    "test_dict = dict(zip(unique_test, counts_test))\n",
    "\n",
    "# Определяем конфигурацию\n",
    "config = {\n",
    "    \"model\": {\n",
    "        \"architecture\": \"MultiBranchECGNet\",\n",
    "        \"num_channels\": 8,\n",
    "        \"num_classes\": 2,\n",
    "        \"parameters\": {\"learning_rate\": 0.001, \"dropout_rate\": 0.1},\n",
    "    },\n",
    "    \"optimizer\": {\"type\": \"Adam\", \"parameters\": {\"lr\": 0.001, \"weight_decay\": 1e-5}},\n",
    "    \"loss_function\": {\n",
    "        \"type\": \"FocalLoss\",\n",
    "        \"parameters\": {\"alpha\": 1.0, \"gamma\": 1, \"pos_weight\": [1, 3]},\n",
    "    },\n",
    "    \"dataset\": {\n",
    "        \"train_size\": len(train_dataset),\n",
    "        \"test_size\": len(test_dataset),\n",
    "        \"class_distribution\": {\n",
    "            \"train\": {0 : int(train_dict[0]), 1: int(train_dict[1])},\n",
    "            \"test\": {0 : int(test_dict[0]), 1: int(test_dict[1])},\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# Сохраняем в файл\n",
    "with open(\"config.yaml\", \"w\") as f:\n",
    "    yaml.dump(config, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ECGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGNet, self).__init__()\n",
    "\n",
    "        # Сверточные слои\n",
    "        self.conv1 = nn.Conv1d(in_channels=8, out_channels=16, kernel_size=7, padding=3)\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=16, out_channels=32, kernel_size=5, padding=2\n",
    "        )\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        # LSTM слой для захвата временных зависимостей\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=32,\n",
    "            hidden_size=64,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "\n",
    "        # Полносвязные слои\n",
    "        self.fc1 = nn.Linear(64 * 2, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)  # Предполагается 3 класса болезней\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, 8, seq_len]\n",
    "\n",
    "        # Свертка\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        # Подготовка для LSTM\n",
    "        # Меняем размер на [batch_size, seq_len, channels] для LSTM\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # LSTM\n",
    "        x, (hn, cn) = self.lstm(x)\n",
    "\n",
    "        # Берем последнее скрытое состояние LSTM\n",
    "        x = x[:, -1, :]  # [batch_size, 64*2]\n",
    "\n",
    "        # Полносвязные слои\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # [batch_size, num_classes]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiBranchECGNet(nn.Module):\n",
    "    def __init__(self, num_channels=8, num_classes=3):\n",
    "        super(MultiBranchECGNet, self).__init__()\n",
    "\n",
    "        # Ветви для каждого канала (CNN)\n",
    "        self.branches = nn.ModuleList(\n",
    "            [self.create_branch() for _ in range(num_channels)]\n",
    "        )\n",
    "\n",
    "        # Attention слой для агрегации информации между каналами\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=128, num_heads=8, batch_first=True\n",
    "        )\n",
    "\n",
    "        # Линейный слой для выравнивания размерности перед attention\n",
    "        self.linear_attn = nn.Linear(num_channels * 128, 128)\n",
    "\n",
    "        # Полносвязные слои для классификации\n",
    "        self.fc1 = nn.Linear(128, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        self.drop = nn.Dropout(p=config[\"model\"][\"parameters\"][\"dropout_rate\"])\n",
    "\n",
    "    def create_branch(self):\n",
    "        \"\"\"Создаем сверточную ветвь для каждого канала\"\"\"\n",
    "        branch = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=7, padding=3),  # Свертка с padding\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(32, 64, kernel_size=5, padding=2),  # Вторая сверточная операция\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),  # Третья сверточная операция\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "        )\n",
    "        return branch\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, num_channels, seq_len]\n",
    "\n",
    "        # Обрабатываем каждый канал через свою ветвь (CNN для каждого канала)\n",
    "        branch_outputs = []\n",
    "        for i in range(x.size(1)):  # num_channels\n",
    "            branch_output = self.branches[i](\n",
    "                x[:, i : i + 1, :]\n",
    "            )  # Обрабатываем i-й канал, [batch_size, 1, seq_len]\n",
    "            branch_outputs.append(branch_output)\n",
    "\n",
    "        # Объединяем выходы ветвей\n",
    "        out = torch.stack(\n",
    "            branch_outputs, dim=1\n",
    "        )  # [batch_size, num_channels, 128, reduced_seq_len]\n",
    "\n",
    "        # out = out.mean(dim=-1)  # Усредняем по временной оси: [batch_size, num_channels, 128]\n",
    "\n",
    "        # # Применяем multi-head attention для межканальной агрегации\n",
    "        # out, _ = self.attention(out, out, out)  # [batch_size, num_channels, 128]\n",
    "\n",
    "        # # Flatten the output\n",
    "        # out = torch.flatten(out, start_dim=1, end_dim=2)  # [batch_size, num_channels * 128]\n",
    "\n",
    "        # Меняем форму, чтобы соответствовать входу MultiheadAttention: [batch_size, reduced_seq_len, num_channels * 128]\n",
    "        batch_size, num_channels, embed_dim, seq_len = out.shape\n",
    "        out = out.permute(0, 3, 1, 2).reshape(batch_size, seq_len, -1)\n",
    "\n",
    "        out = F.relu(self.linear_attn(out))\n",
    "\n",
    "        # Применяем Multihead Attention ко всей последовательности\n",
    "        out, _ = self.attention(\n",
    "            out, out, out\n",
    "        )  # [batch_size, seq_len, num_channels * 128]\n",
    "\n",
    "        # Усредняем по временной оси\n",
    "        out = out.mean(dim=1)  # [batch_size, num_channels * 128]\n",
    "\n",
    "        # Полносвязные слои для классификации\n",
    "        out = F.relu(self.drop(self.fc1(out)))\n",
    "        out = self.fc2(out)  # [batch_size, num_classes]\n",
    "        return out\n",
    "\n",
    "\n",
    "# Пример использования\n",
    "model = MultiBranchECGNet(num_channels=8, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction=\"mean\"):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "        if self.reduction == \"mean\":\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.3385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kravchenko.artem/Projects/Diplomas/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Loss: 0.3141\n",
      "Epoch 3/50, Loss: 0.2928\n",
      "Epoch 4/50, Loss: 0.2659\n",
      "Epoch 5/50, Loss: 0.2317\n",
      "Epoch 6/50, Loss: 0.2314\n",
      "Epoch 7/50, Loss: 0.2276\n",
      "Epoch 8/50, Loss: 0.1775\n",
      "Epoch 9/50, Loss: 0.1879\n",
      "Epoch 10/50, Loss: 0.1769\n",
      "Epoch 11/50, Loss: 0.1475\n",
      "Epoch 12/50, Loss: 0.1343\n",
      "Epoch 13/50, Loss: 0.1918\n",
      "Epoch 14/50, Loss: 0.1394\n",
      "Epoch 15/50, Loss: 0.1268\n",
      "Epoch 16/50, Loss: 0.1009\n",
      "Epoch 17/50, Loss: 0.0892\n",
      "Epoch 18/50, Loss: 0.0624\n",
      "Epoch 19/50, Loss: 0.0657\n",
      "Epoch 20/50, Loss: 0.0582\n",
      "Epoch 21/50, Loss: 0.0676\n",
      "Epoch 22/50, Loss: 0.0784\n",
      "Epoch 23/50, Loss: 0.0559\n",
      "Epoch 24/50, Loss: 0.0478\n",
      "Epoch 25/50, Loss: 0.0322\n",
      "Epoch 26/50, Loss: 0.1175\n",
      "Epoch 27/50, Loss: 0.0859\n",
      "Epoch 28/50, Loss: 0.0617\n",
      "Epoch 29/50, Loss: 0.0376\n",
      "Epoch 30/50, Loss: 0.0324\n",
      "Epoch 31/50, Loss: 0.0180\n",
      "Epoch 32/50, Loss: 0.0192\n",
      "Epoch 33/50, Loss: 0.0095\n",
      "Epoch 34/50, Loss: 0.0058\n",
      "Epoch 35/50, Loss: 0.0134\n",
      "Epoch 36/50, Loss: 0.0415\n",
      "Epoch 37/50, Loss: 0.0257\n",
      "Epoch 38/50, Loss: 0.0172\n",
      "Epoch 39/50, Loss: 0.0124\n",
      "Epoch 40/50, Loss: 0.0039\n",
      "Epoch 41/50, Loss: 0.0241\n",
      "Epoch 42/50, Loss: 0.0810\n",
      "Epoch 43/50, Loss: 0.0501\n",
      "Epoch 44/50, Loss: 0.0334\n",
      "Epoch 45/50, Loss: 0.0279\n",
      "Epoch 46/50, Loss: 0.0076\n",
      "Epoch 47/50, Loss: 0.0175\n",
      "Epoch 48/50, Loss: 0.0940\n",
      "Epoch 49/50, Loss: 0.0650\n",
      "Epoch 50/50, Loss: 0.0222\n"
     ]
    }
   ],
   "source": [
    "loss_type = config[\"loss_function\"][\"type\"]\n",
    "\n",
    "if loss_type == \"FocalLoss\":\n",
    "    criterion = FocalLoss(\n",
    "        alpha=config[\"loss_function\"][\"parameters\"][\"alpha\"],\n",
    "        gamma=config[\"loss_function\"][\"parameters\"][\"gamma\"],\n",
    "    )\n",
    "elif loss_type == \"BCEWithLogitsLoss\":\n",
    "    pos_weight = torch.tensor(config[\"loss_function\"][\"parameters\"][\"pos_weight\"])\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown loss function type: {loss_type}\")\n",
    "\n",
    "# criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "# criterion = FocalLoss(alpha=2, gamma=3)\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=config[\"optimizer\"][\"parameters\"][\"lr\"],\n",
    "    weight_decay=config[\"optimizer\"][\"parameters\"][\"weight_decay\"],\n",
    ")\n",
    "\n",
    "\n",
    "# Обучение модели\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=10, patience=10):\n",
    "    best_valid_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        for inputs, labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            # labels.type(torch.FloatTensor)\n",
    "\n",
    "            # labels = labels.type(torch.FloatTensor) \\\n",
    "            #   .reshape((labels.shape[0], 2))epoch_loss\n",
    "\n",
    "            labels = F.one_hot(labels, num_classes=2).float()\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            all_preds.extend(torch.argmax(outputs, dim=1))\n",
    "            all_labels.extend(torch.argmax(labels, dim=1))\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        recall = recall_score(all_labels, all_preds)\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        precision = precision_score(all_labels, all_preds)\n",
    "\n",
    "        Logger.current_logger().report_scalar(\"Accuracy\", \"Train\", accuracy, epoch)\n",
    "        Logger.current_logger().report_scalar(\"Loss\", \"Train\", epoch_loss, epoch)\n",
    "        Logger.current_logger().report_scalar(\"Recall\", \"Train\", recall, epoch)\n",
    "        Logger.current_logger().report_scalar(\"Precision\", \"Train\", precision, epoch)\n",
    "\n",
    "        mlflow.log_metric(\"Train Accuracy\", accuracy, step=epoch)\n",
    "        mlflow.log_metric(\"Train Loss\", epoch_loss, step=epoch)\n",
    "        mlflow.log_metric(\"Train Recall\", recall, step=epoch)\n",
    "        mlflow.log_metric(\"Train Precision\", precision, step=epoch)\n",
    "        \n",
    "        if abs(epoch_loss - best_valid_loss) > 0.001:\n",
    "            best_valid_loss = epoch_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "        # if epoch_loss < best_valid_loss:\n",
    "        #     best_valid_loss = epoch_loss\n",
    "        #     print(f\"\\nBest validation loss: {best_valid_loss}\")\n",
    "        #     print(f\"\\nSaving best model for epoch: {epoch+1}\\n\")\n",
    "        #     torch.save(model.state_dict(), \"model_weights.pth\")\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "\n",
    "# Запуск обучения\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-24 15:07:10,701 - clearml.frameworks - INFO - Found existing registered model id=078a530219b44bd5b8f841b1a246c02b [/home/kravchenko.artem/Projects/Diplomas/Classifiers/NN/model_weights.pth] reusing it.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сохранение модели\n",
    "torch.save(model.state_dict(), \"model_weights.pth\")\n",
    "task.upload_artifact(name=\"Model Weights\", artifact_object=\"model_weights.pth\")\n",
    "\n",
    "# Сохранение конфигурации\n",
    "task.upload_artifact(name=\"Config File\", artifact_object=\"config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation recall: 0.6250\n",
      "Validation accuracy: 0.7917\n",
      "Validation precision: 0.4167\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87        40\n",
      "           1       0.42      0.62      0.50         8\n",
      "\n",
      "    accuracy                           0.79        48\n",
      "   macro avg       0.67      0.72      0.68        48\n",
      "weighted avg       0.83      0.79      0.81        48\n",
      "\n",
      "Матрица несоответствий для тестовой выборки метода ЛДА:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def validate_model(model, dataloader):\n",
    "    model = MultiBranchECGNet(num_channels=8, num_classes=2)\n",
    "    model.load_state_dict(torch.load(\"model_weights.pth\", weights_only=True))\n",
    "    model.eval()  # Переводим модель в режим оценки\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():  # Отключаем градиенты для валидации\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)  # Предсказания с максимальной вероятностью\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    # Преобразуем в numpy массивы\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    # all_labels = np.argmax(all_labels, axis=1)\n",
    "\n",
    "    # Считаем accuracy\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    print(f\"Validation recall: {recall:.4f}\")\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Validation accuracy: {accuracy:.4f}\")\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    print(f\"Validation precision: {precision:.4f}\")\n",
    "\n",
    "    class_names = [\"Норм. ритм\", \"Амилоидоз\"]\n",
    "\n",
    "    print(\"\\n clasification report:\\n\", classification_report(all_labels, all_preds))\n",
    "\n",
    "    print(\"Матрица несоответствий для тестовой выборки метода ЛДА:\\n\")\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    disp = ConfusionMatrixDisplay(\n",
    "        confusion_matrix(all_labels, all_preds), display_labels=class_names\n",
    "    )\n",
    "    disp.plot(cmap=\"Blues\", ax=ax)\n",
    "\n",
    "    Logger.current_logger().report_confusion_matrix(\n",
    "        title=\"Confusion Matrix\",\n",
    "        series=\"Validation Results\",\n",
    "        matrix=confusion_matrix(all_labels, all_preds),\n",
    "        yaxis_reversed=True,\n",
    "        xaxis=\"Predicted\",\n",
    "        yaxis=\"Expected\",\n",
    "        xlabels=class_names,\n",
    "        ylabels=class_names\n",
    "    )\n",
    "\n",
    "    return recall\n",
    "\n",
    "\n",
    "# Пример вызова валидации\n",
    "test_accuracy = validate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()\n",
    "task.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
